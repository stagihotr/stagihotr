<?xml version="1.0"?>
<doc>
    <assembly>
        <name>KafkaNET.Library</name>
    </assembly>
    <members>
        <member name="T:Kafka.Client.Cfg.ConsumerConfiguration">
            <summary>
            Configuration used by the simple consumer api and consumer group.
            When use consumer group, need tune MaxFetchBufferLength, BufferSize, FetchSize according to different message size.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.NumberOfTries">
            <summary>
            The number of retry for get response.
            Default value: 2
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.SendTimeout">
            <summary>
            The Socket send timeout. in milliseconds.
            Default value 30*1000
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.ReceiveTimeout">
            <summary>
            The Socket recieve time out. in milliseconds.
            Default value 30*1000
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.ReconnectInterval">
            <summary>
            The Socket reconnect interval. in milliseconds.
            Default value 60*1000
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.BufferSize">
            <summary>
            The socket recieve / send buffer size. in bytes.
            Map to socket.receive.buffer.bytes in java api.
            Default value 11 * 1024 * 1024
            java version original default  value: 64 *1024
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.Broker">
            <summary>
            Broker:  BrokerID, Host, Port
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.Verbose">
            <summary>
            Log level is verbose or not
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.FetchSize">
            <summary>
            Consumer group API only.
            the number of byes of messages to attempt to fetch. 
            map to fetch.message.max.bytes of java version.
            Finally it call FileChannle.position(long newPosition)  and got to native call position0(FileDescriptor fd, long offset)
            Default value: 11 * 1024*1024
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.FetchMinBytes">
            <summary>
            fetch.min.bytes -
            The minimum amount of data the server should return for a fetch request. If insufficient data is available the request will wait for that much data to accumulate before answering the request.
            Default value: 1
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.MaxFetchWaitMs">
            <summary>
            fetch.wait.max.ms -
            The maximum amount of time the server will block before answering the fetch request if there isn't sufficient data to immediately satisfy fetch.min.bytes.
            Default value: 100
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.ZooKeeper">
            <summary>
            Consumer Group API only. Zookeeper
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.GroupId">
            <summary>
            Consumer Group API only.  The group name of consumer group, should not be empty.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.Timeout">
            <summary>
            Consumer Group API only. The time out of get data from the BlockingCollection of KafkaMessageStream. in milliseconds.
            If the value less than 0, it will block there is no data available.
            If the value bigger of equal than 0 and got time out , one ConsumerTimeoutException will be thrown.
            Default value: -1
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.ShutdownTimeout">
            <summary>
            Consumer Group API only.  The time out of shutting down fetcher thread. in milliseconds.
            Default value: 10,000
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.AutoOffsetReset">
            <summary>
            Consumer Group API only. Where to reset offset after got ErrorMapping.OffsetOutOfRangeCode.
            Valid value: OffsetRequest.SmallestTime  or OffsetRequest.LargestTime
            Default value: OffsetRequest.SmallestTime
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.AutoCommit">
            <summary>
            Consumer Group API only.  Automate commit offset or not.
            Default value: true
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.AutoCommitInterval">
            <summary>
            Consumer Group API only.  The interval of commit offset. in milliseconds.
            Default value: 10,000
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.MaxFetchBufferLength">
            <summary>
            Consumer Group API only. The count of message trigger fetcher thread cache, if the message count in fetch thread less than it, it will try fetch more from kafka.
            Default value: 1000
            Should be : (5~10 even 100) *  FetchSize / average message size  
            If this value set too big, your exe will use more memory to cache data.
            If this valuse set too small, your exe will raise more request to Kafka. 
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.BackOffIncrement">
            <summary>
            Consumer Group API only.  the time of sleep when no data to fetch. in milliseconds.
            Default value: 1000
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.ConsumerId">
            <summary>
            Consumer group only. 
            Default value: host name
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.ConsumeGroupRebalanceRetryIntervalMs">
            <summary>
            Consumer group only.
            Default value : 1000 ms.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.ConsumeGroupFindNewLeaderSleepIntervalMs">
            <summary>
            Consumer group only.
            Default value: 2000ms
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.MaxFetchSize">
            <summary>
            No place use it now.  Why it here?
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ConsumerConfiguration.MaxFetchFactor">
            <summary>
            No place use it now.  Why it here?
            </summary>
        </member>
        <member name="T:Kafka.Client.Cfg.KafkaSimpleManagerConfiguration">
            <summary>
            Contains main fields of ProducerConfiguration and ConsumerConfiguration
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.KafkaSimpleManagerConfiguration.MaxMessageSize">
            <summary>
            ProducerConfiguration  - Max size of one message, used for verify size and throw exception.
            Default: 1 M
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.KafkaSimpleManagerConfiguration.AckTimeout">
            <summary>
            ProducerConfiguration ==== AckTimeout  Ack Timeout. Default to 300 milliseconds
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.KafkaSimpleManagerConfiguration.PartitionerClass">
            <summary>
            ProducerConfiguration ==== PartitionerClass. Default is empty.
            If this value is null/empty,   the kafkaSimpleManager will create on producer for each partition.
            Else if this value is one partitioner class full name, the kafkaSimpleManager will only create one producer.  And that producer has internal syncproducer pool to partition data by the class and send data.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.KafkaSimpleManagerConfiguration.BufferSize">
            <summary>
            ProducerConfiguration - ConsumerConfiguration - The socket recieve / send buffer size. in bytes.
            Map to socket.receive.buffer.bytes in java api.
            Default value 11 * 1024 * 1024
            java version original default  value: 64 *1024
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.KafkaSimpleManagerConfiguration.Verbose">
            <summary>
            Log is verbose or not
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.KafkaSimpleManagerConfiguration.FetchSize">
            <summary>
            Consume API ==== FetchRequest - the number of byes of messages to attempt to fetch. 
            map to fetch.message.max.bytes of java version.
            Finally it call FileChannle.position(long newPosition)  and got to native call position0(FileDescriptor fd, long offset)
            Default value: 11 * 1024*1024
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.KafkaSimpleManagerConfiguration.MaxWaitTime">
            <summary>
            Consume API ==== FetchRequest MaxWait
            http://kafka.apache.org/documentation.html#simpleconsumerapi, 
            https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-FetchRequest
            fetch.wait.max.ms, 100ms, The maximum amount of time the server will block before answering the fetch request if there isn't sufficient data to immediately satisfy fetch.min.bytes
            Observation: if message is pushed to Kafka during the wait, somehow the client is still blocked on the wait, 
            Recommend to set this value based on the understanding of the message arrival rate in Kafka. 
            https://kafka.apache.org/08/configuration.html
            Default value  to 0 ms.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.KafkaSimpleManagerConfiguration.MinWaitBytes">
            <summary>
            Consume API ==== FetchRequest MinBytes
            Use together with previous one MaxWaitTime
            fetch.min.bytes
            default value 0 
            </summary>
        </member>
        <member name="T:Kafka.Client.Cfg.ProducerConfiguration">
            <summary>
            High-level API configuration for the producer
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ProducerConfiguration.IsZooKeeperEnabled">
            <summary>
            Gets a value indicating whether ZooKeeper based automatic broker discovery is enabled.
            </summary>
            <value>
            <c>true</c> if this instance is zoo keeper enabled; otherwise, <c>false</c>.
            </value>
        </member>
        <member name="P:Kafka.Client.Cfg.ProducerConfiguration.ReceiveTimeout">
            <summary>
            Socket recieve timeout , defautl 5000 ms.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ProducerConfiguration.SendTimeout">
            <summary>
            Socket send timeout , default 5000 ms.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ProducerConfiguration.MaxMessageSize">
            <summary>
            Max size of one message, used for verify size and throw exception.
            Default: 1 M
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ProducerConfiguration.RequiredAcks">
            <summary>
            https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol#AGuideToTheKafkaProtocol-ProduceRequest
            RequiredAcks: This field indicates how many acknowledgements the servers should receive before responding to the request.
                If it is 0 the server will not send any response (this is the only case where the server will not reply to a request). 
                If it is 1, the server will wait the data is written to the local log before sending a response. 
                If it is -1 the server will block until the message is committed by all in sync replicas before sending a response. 
                For any number > 1 the server will block waiting for this number of acknowledgements to occur (but the server will never wait for 
                    more acknowledgements than there are in-sync replicas). 
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ProducerConfiguration.AckTimeout">
            <summary>
            ACK timeout, default 300ms.
            If you set RequiredAcks as one big value or -1, need change this value big.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cfg.ProducerConfiguration.TotalNumPartitions">
            <summary>
            Total partition number of topic. Default value 0.
            if not set, will take the partitions which hav metadata available.
            Please ALWAYS keep this number as 0. 
            </summary>
        </member>
        <member name="T:Kafka.Client.Consumers.Consumer">
            <summary>
            The low-level API of consumer of Kafka messages
            </summary>
            <remarks>
            Maintains a connection to a single broker and has a close correspondence
            to the network requests sent to the server.
            Also, is completely stateless.
            </remarks>
        </member>
        <member name="M:Kafka.Client.Consumers.Consumer.#ctor(Kafka.Client.Cfg.ConsumerConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Consumers.Consumer"/> class.
            </summary>
            <param name="config">
            The consumer configuration.
            </param>
        </member>
        <member name="M:Kafka.Client.Consumers.Consumer.#ctor(Kafka.Client.Cfg.ConsumerConfiguration,System.String,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Consumers.Consumer"/> class.
            </summary>
            <param name="config">
            The consumer configuration.
            </param>
            <param name="host"></param>
            <param name="port"></param>
        </member>
        <member name="M:Kafka.Client.Consumers.Consumer.FetchAndGetDetail(System.String,System.String,System.Int32,System.Int32,System.Int64,System.Int32,System.Int32,System.Int32)">
            <summary>
            MANIFOLD use
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.Consumer.GetOffsetsBefore(Kafka.Client.Requests.OffsetRequest)">
            <summary>
            Gets a list of valid offsets (up to maxSize) before the given time.
            </summary>
            <param name="request">
            The offset request.
            </param>
            <returns>
            The list of offsets, in descending order.
            </returns>
        </member>
        <member name="T:Kafka.Client.Consumers.ConsumerGroupStatisticsRecord">
            <summary>
            Represent statistics or state of consumer group such as offsets positions in different topics and lags between reading position and queue size.
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.ConsumerGroupStatisticsRecord.ConsumerGroupName">
            <summary>
            Gets or sets the name of consumer group
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.ConsumerGroupStatisticsRecord.TopicsStat">
            <summary>
            Gets or sets state for each topic that consumer groups started reading
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.ConsumerGroupStatisticsRecord.Lag">
            <summary>
            Gets the total number of messages in all topics that were not consumed yet.
            </summary>
        </member>
        <member name="T:Kafka.Client.Consumers.ConsumerIterator`1">
            <summary>
            An iterator that blocks until a value can be read from the supplied queue.
            </summary>
            <remarks>
            The iterator takes a shutdownCommand object which can be added to the queue to trigger a shutdown
            </remarks>
        </member>
        <member name="M:Kafka.Client.Consumers.ConsumerIterator`1.#ctor(System.String,System.Collections.Concurrent.BlockingCollection{Kafka.Client.Consumers.FetchedDataChunk},System.Int32,Kafka.Client.Serialization.IDecoder{`0})">
            <summary>
            Initializes a new instance of the <see cref="!:ConsumerIterator"/> class.
            </summary>
            <param name="channel">
            The queue containing 
            </param>
            <param name="consumerTimeoutMs">
            The consumer timeout in ms.
            </param>
        </member>
        <member name="M:Kafka.Client.Consumers.ConsumerIterator`1.#ctor(System.String,System.Collections.Concurrent.BlockingCollection{Kafka.Client.Consumers.FetchedDataChunk},System.Int32,Kafka.Client.Serialization.IDecoder{`0},System.Threading.CancellationToken)">
            <summary>
            Initializes a new instance of the <see cref="!:ConsumerIterator"/> with a <see cref="T:System.Threading.CancellationToken"/>
            </summary>
            <param name="channel">The queue containing</param>
            <param name="consumerTimeoutMs">The consumer timeout in ms</param>
            <param name="cacellationToken">The <see cref="T:System.Threading.CancellationToken"/> to allow for clean task cancellation</param>
        </member>
        <member name="P:Kafka.Client.Consumers.ConsumerIterator`1.Current">
            <summary>
            Gets the element in the collection at the current position of the enumerator.
            </summary>
            <returns>
            The element in the collection at the current position of the enumerator.
            </returns>
        </member>
        <member name="P:Kafka.Client.Consumers.ConsumerIterator`1.System#Collections#IEnumerator#Current">
            <summary>
            Gets the current element in the collection.
            </summary>
            <returns>
            The current element in the collection.
            </returns>
        </member>
        <member name="M:Kafka.Client.Consumers.ConsumerIterator`1.MoveNext">
            <summary>
            Advances the enumerator to the next element of the collection.
            </summary>
            <returns>
            true if the enumerator was successfully advanced to the next element; false if the enumerator has passed the end of the collection.
            </returns>
        </member>
        <member name="M:Kafka.Client.Consumers.ConsumerIterator`1.Reset">
            <summary>
            Resets the enumerator's state to NotReady.
            </summary>
        </member>
        <member name="T:Kafka.Client.Consumers.Fetcher">
            <summary>
            Background thread that fetches data from a set of servers
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.Fetcher.#ctor(Kafka.Client.Cfg.ConsumerConfiguration,Kafka.Client.ZooKeeperIntegration.IZooKeeperClient)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Consumers.Fetcher" /> class.
            </summary>
            <param name="config">
            The consumer configuration.
            </param>
            <param name="zkClient">
            The wrapper above ZooKeeper client.
            </param>
        </member>
        <member name="M:Kafka.Client.Consumers.Fetcher.Shutdown">
            <summary>
            Shuts down all fetch threads
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.Fetcher.InitConnections(System.Collections.Generic.IEnumerable{Kafka.Client.Consumers.PartitionTopicInfo},Kafka.Client.Cluster.Cluster)">
            <summary>
            Opens connections to brokers.
            </summary>
            <param name="topicInfos">
            The topic infos.
            </param>
            <param name="cluster">
            The cluster.
            </param>
            <param name="queuesToBeCleared">
            The queues to be cleared.
            </param>
        </member>
        <member name="M:Kafka.Client.Consumers.Fetcher.EnsuresNotDisposed">
            <summary>
            Ensures that object was not disposed
            </summary>
        </member>
        <member name="T:Kafka.Client.Consumers.FetcherRunnable">
            <summary>
            Background thread worker class that is used to fetch data from a single broker
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.FetcherRunnable.Run">
            <summary>
            Method to be used for starting a new thread
            </summary>
        </member>
        <member name="T:Kafka.Client.Consumers.IConsumer">
            <summary>
            The low-level API of consumer of Kafka messages
            </summary>
            <remarks>
            Maintains a connection to a single broker and has a close correspondence 
            to the network requests sent to the server.
            </remarks>
        </member>
        <member name="M:Kafka.Client.Consumers.IConsumer.Fetch(Kafka.Client.Requests.FetchRequest)">
            <summary>
            Fetch a set of messages from a topic.
            </summary>
            <param name="request">
            Specifies the topic name, topic partition, starting byte offset, maximum bytes to be fetched.
            </param>
            <returns>
            A set of fetched messages.
            </returns>
            <remarks>
            Offset is passed in on every request, allowing the user to maintain this metadata 
            however they choose.
            </remarks>
        </member>
        <member name="M:Kafka.Client.Consumers.IConsumer.GetOffsetsBefore(Kafka.Client.Requests.OffsetRequest)">
            <summary>
            Gets a list of valid offsets (up to maxSize) before the given time.
            </summary>
            <param name="request">
            The offset request.
            </param>
            <returns>
            The list of offsets, in descending order.
            </returns>
        </member>
        <member name="T:Kafka.Client.Consumers.IConsumerConnector">
            <summary>
            The consumer high-level API, that hides the details of brokers from the consumer 
            It also maintains the state of what has been consumed. 
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.IConsumerConnector.CreateMessageStreams``1(System.Collections.Generic.IDictionary{System.String,System.Int32},Kafka.Client.Serialization.IDecoder{``0})">
            <summary>
            Creates a list of message streams for each topic.
            </summary>
            <param name="topicCountDict">
            The map of topic on number of streams
            </param>
            <returns>
            The list of <see cref="!:KafkaMessageStream"/>, which are iterators over topic.
            </returns>
        </member>
        <member name="M:Kafka.Client.Consumers.IConsumerConnector.CommitOffsets">
            <summary>
            Commits the offsets of all messages consumed so far.
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.IConsumerConnector.CommitOffset(System.String,System.Int32,System.Int64,System.Boolean)">
            <summary>
            Do manually commit offset.  When use this API, The AutoCommit should be false.
            Use it when process time of message are very vary. For example,
            Read message with offset 0,1,2,3,4,5,6,7,8...
            But message 3 process take very long time.
            Firstly 0,1,2 has been processed, you can commit offset 2
            Then 4,5,6 has been processed, do not commit offset
            Then 3 has been processed, then you can directly commit offset 6.
            Potential risk is that, before you commit 3, the running process crashed (for exmaple, autopilog IMP), then after restart
            Message 3,4,5,6 will be Reprocessed.
            </summary>
            <param name="topic">The topic </param>
            <param name="partition">The partition</param>
            <param name="offset">The offset</param>
            <param name="setPosition">Indicates whether to set the fetcher's offset to the value committed. Default = true.</param>
        </member>
        <member name="M:Kafka.Client.Consumers.IConsumerConnector.GetOffset(System.String)">
            <summary>
            Return offsets of current ConsumerGroup
            </summary>
            <param name="topic"></param>
            <returns></returns>
        </member>
        <member name="T:Kafka.Client.Consumers.KafkaMessageStream`1">
            <summary>
            This class is a thread-safe IEnumerable of <see cref="T:Kafka.Client.Messages.Message"/> that can be enumerated to get messages.
            </summary>
        </member>
        <member name="T:Kafka.Client.Consumers.PartitionStatisticsRecord">
            <summary>
            Represent the statistics or state of consuming a partition
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionStatisticsRecord.PartitionId">
            <summary>
            Gets or sets the Partition Id
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionStatisticsRecord.OwnerConsumerId">
            <summary>
            Gets or sets the ConsumerId that currently owns reading the partition.
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionStatisticsRecord.CurrentOffset">
            <summary>
            Gets or sets offset of last committed message read from the partition
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionStatisticsRecord.LastOffset">
            <summary>
            Gets or sets offset of last message written to the partition
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionStatisticsRecord.Lag">
            <summary>
            Gets the number of messages between last consumed message and last message in partition
            </summary>
        </member>
        <member name="T:Kafka.Client.Consumers.PartitionTopicInfo">
            <summary>
            Represents topic in brokers's partition.
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.PartitionTopicInfo.#ctor(System.String,System.Int32,System.Int32,System.Collections.Concurrent.BlockingCollection{Kafka.Client.Consumers.FetchedDataChunk},System.Int64,System.Int64,System.Int64,System.Int32,System.Int64)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Consumers.PartitionTopicInfo"/> class.
            </summary>
            <param name="topic">
            The topic.
            </param>
            <param name="brokerId">
            The broker ID.
            </param>
            <param name="partition">
            The broker's partition.
            </param>
            <param name="chunkQueue">
            The chunk queue.
            </param>
            <param name="consumedOffset">
            The consumed offset value.
            </param>
            <param name="fetchedOffset">
            The fetched offset value.
            </param>
            <param name="fetchSize">
            The fetch size.
            </param>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionTopicInfo.BrokerId">
            <summary>
            Gets broker ID.
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionTopicInfo.FetchSize">
            <summary>
            Gets the fetch size.
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionTopicInfo.PartitionId">
            <summary>
            Gets the partition Id.
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionTopicInfo.Topic">
            <summary>
            Gets the topic.
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionTopicInfo.ConsumeOffset">
            <summary>
            Last read out from Iterator
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionTopicInfo.CommitedOffset">
            <summary>
            Last commited to zookeeper
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionTopicInfo.ConsumeOffsetValid">
            <summary>
            Gets or sets a flag which indicates if the current consumed offset is valid
            and should be used during updates to ZooKeeper.
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.PartitionTopicInfo.FetchOffset">
            <summary>
            Last fetched offset from Kafka
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.PartitionTopicInfo.Add(Kafka.Client.Messages.BufferedMessageSet)">
            <summary>
            Ads a message set to the queue
            </summary>
            <param name="messages">The message set</param>
            <returns>The set size</returns>
        </member>
        <member name="T:Kafka.Client.Consumers.TopicStatisticsRecord">
            <summary>
            Represent current state of consuming specified topic
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.TopicStatisticsRecord.Topic">
            <summary>
            Gets or sets topic name
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.TopicStatisticsRecord.PartitionsStat">
            <summary>
            Gets or sets statistics for each partition within a topic
            </summary>
        </member>
        <member name="P:Kafka.Client.Consumers.TopicStatisticsRecord.Lag">
            <summary>
            Gets the total number of messages in all topics that were not consumed yet.
            </summary>
        </member>
        <member name="T:Kafka.Client.Consumers.ZookeeperConsumerConnector">
            <summary>
            The consumer high-level API, that hides the details of brokers from the consumer. 
            It also maintains the state of what has been consumed. 
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.ZookeeperConsumerConnector.#ctor(Kafka.Client.Cfg.ConsumerConfiguration,System.Boolean,System.EventHandler,System.EventHandler,System.EventHandler,System.EventHandler{Kafka.Client.ZooKeeperIntegration.Events.ConsumerRebalanceEventArgs})">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Consumers.ZookeeperConsumerConnector"/> class.
            </summary>
            <param name="config">
            The consumer configuration. At the minimum, need to specify the group ID 
            of the consumer and the ZooKeeper connection string.
            </param>
            <param name="enableFetcher">
            Indicates whether fetchers should be enabled
            </param>
        </member>
        <member name="P:Kafka.Client.Consumers.ZookeeperConsumerConnector.ConsumerGroup">
            <summary>
            Gets the consumer group ID.
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.ZookeeperConsumerConnector.GetCurrentOwnership">
            <summary>
            Gets the current ownership.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Consumers.ZookeeperConsumerConnector.CommitOffsets">
            <summary>
            Commits the offsets of all messages consumed so far.
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.ZookeeperConsumerConnector.CommitOffset(System.String,System.Int32,System.Int64,System.Boolean)">
            <summary>
            Commit offset of specified topic/partition.
            Only used when customer has strong requirement for reprocess messages as few as possible.
            </summary>
            <param name="topic"></param>
            <param name="partition"></param>
            <param name="offset"></param>
            <param name="setPosition">Indicates whether to set the fetcher's offset to the value committed. Default = true.</param>
        </member>
        <member name="M:Kafka.Client.Consumers.ZookeeperConsumerConnector.CreateMessageStreams``1(System.Collections.Generic.IDictionary{System.String,System.Int32},Kafka.Client.Serialization.IDecoder{``0})">
            <summary>
            Creates a list of message streams for each topic.
            </summary>
            <param name="topicCountDict">
            The map of topic on number of streams
            </param>
            <returns>
            The list of <see cref="!:KafkaMessageStream"/>, which are iterators over topic.
            </returns>
            <remarks>
            Explicitly triggers load balancing for this consumer
            </remarks>
        </member>
        <member name="M:Kafka.Client.Consumers.ZookeeperConsumerConnector.EnsuresNotDisposed">
            <summary>
            Ensures that object was not disposed
            </summary>
        </member>
        <member name="M:Kafka.Client.Consumers.KafkaClientHelperUtils.ToUnixTimestampMillis(System.DateTime)">
            <summary>
            The offset time in kafka is UTC
            </summary>
            <param name="time"></param>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Consumers.KafkaClientHelperUtils.ToZookeeperConfig(System.String)">
            <summary>
            Convert Zookeeper string to ZookeeperConfiguration
            </summary>
            <param name="zookeeperAddress"></param>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Consumers.KafkaClientHelperUtils.ToBrokerConfig(System.String)">
            <summary>
            Convert a broker string into a BrokerConfiguration.
            </summary>
            <param name="brokerAddr">Broker string must follow the format of {Broker-ID},{Host}:{Port}</param>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Consumers.KafkaClientHelperUtils.TryCreateSyncProducer(System.Int32,System.String,System.Int32)">
            <summary>
            SyncProducer makes a connection to the broker inside constructor
            </summary>
            <param name="brokerId"></param>
            <param name="host"></param>
            <param name="port"></param>
            <returns></returns>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Events.ChildChangedEventItem">
            <summary>
            Represents methods that will handle a ZooKeeper child events  
            </summary>
        </member>
        <member name="E:Kafka.Client.ZooKeeperIntegration.Events.ChildChangedEventItem.ChildChanged">
            <summary>
            Occurs when znode children changes
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ChildChangedEventItem.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ChildChangedEventItem"/> class. 
            </summary>
            <param name="logger">
            The logger.
            </param>
            <remarks>
            Should use external logger to keep same format of all event logs
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ChildChangedEventItem.#ctor(Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ZooKeeperEventHandler{Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs})">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ChildChangedEventItem"/> class.
            </summary>
            <param name="logger">
            The logger.
            </param>
            <param name="handler">
            The subscribed handler.
            </param>
            <remarks>
            Should use external logger to keep same format of all event logs
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ChildChangedEventItem.OnChildChanged(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs)">
            <summary>
            Invokes subscribed handlers for ZooKeeeper children changes event
            </summary>
            <param name="e">
            The event data.
            </param>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ChildChangedEventItem.Count">
            <summary>
            Gets the total count of subscribed handlers
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem">
            <summary>
            Represents methods that will handle a ZooKeeper data events  
            </summary>
        </member>
        <member name="E:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem.DataChanged">
            <summary>
            Occurs when znode data changes
            </summary>
        </member>
        <member name="E:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem.DataDeleted">
            <summary>
            Occurs when znode data deletes
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem"/> class.
            </summary>
            <param name="logger">
            The logger.
            </param>
            <remarks>
            Should use external logger to keep same format of all event logs
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem.#ctor(Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ZooKeeperEventHandler{Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs},Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ZooKeeperEventHandler{Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs})">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem"/> class.
            </summary>
            <param name="logger">
            The logger.
            </param>
            <param name="changedHandler">
            The changed handler.
            </param>
            <param name="deletedHandler">
            The deleted handler.
            </param>
            <remarks>
            Should use external logger to keep same format of all event logs
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem.OnDataChanged(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs)">
            <summary>
            Invokes subscribed handlers for ZooKeeeper data changes event
            </summary>
            <param name="e">
            The event data.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem.OnDataDeleted(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs)">
            <summary>
            Invokes subscribed handlers for ZooKeeeper data deletes event
            </summary>
            <param name="e">
            The event data.
            </param>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.DataChangedEventItem.TotalCount">
            <summary>
            Gets the total count of subscribed handlers
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs">
            <summary>
            Contains znode children changed event data
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs"/> class.
            </summary>
            <param name="path">
            The path.
            </param>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs.Path">
            <summary>
            Gets the znode path
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs.Children">
            <summary>
            Gets or sets the current znode children
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs.Type">
            <summary>
            Gets the current event type
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs">
            <summary>
            Contains znode data changed event data
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs"/> class.
            </summary>
            <param name="path">
            The znode path.
            </param>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs.Path">
            <summary>
            Gets the znode path
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs.Data">
            <summary>
            Gets or sets znode changed data.
            </summary>
            <remarks>
            Null if data was deleted.
            </remarks>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs.Type">
            <summary>
            Gets the event type.
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs.DataDeleted">
            <summary>
            Gets a value indicating whether data was deleted
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs.ToString">
            <summary>
            Gets string representation of event data
            </summary>
            <returns>
            String representation of event data
            </returns>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperEventArgs">
            <summary>
            Base class for classes containing ZooKeeper event data
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperEventArgs.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperEventArgs"/> class.
            </summary>
            <param name="description">
            The event description.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperEventArgs.ToString">
            <summary>
            Gets string representation of event data
            </summary>
            <returns>
            String representation of event data
            </returns>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperEventArgs.Type">
            <summary>
            Gets the event type.
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperEventTypes">
            <summary>
            Event types
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperSessionCreatedEventArgs">
            <summary>
            Contains ZooKeeper session created event data
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperSessionCreatedEventArgs.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperSessionCreatedEventArgs"/> class.
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperSessionCreatedEventArgs.Type">
            <summary>
            Gets the event type.
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs">
            <summary>
            Contains ZooKeeper session state changed event data
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs.#ctor(ZooKeeperNet.KeeperState)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs"/> class.
            </summary>
            <param name="state">
            The current ZooKeeper state.
            </param>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs.State">
            <summary>
            Gets current ZooKeeper state
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs.Type">
            <summary>
            Gets the event type.
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient">
            <summary>
            Abstracts the interaction with zookeeper
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.IdleTime">
            <summary>
            Gets time (in miliseconds) of event thread idleness
            </summary>
            <remarks>
            Used for testing purpose
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Connect">
            <summary>
            Connects to ZooKeeper server within given time period and installs watcher in ZooKeeper
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Disconnect">
            <summary>
            Closes current connection to ZooKeeper
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Reconnect(System.String,System.Int32)">
            <summary>
            Re-connect to ZooKeeper server when session expired
            </summary>
            <param name="servers">
            The servers.
            </param>
            <param name="connectionTimeout">
            The connection timeout.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.WaitUntilConnected(System.Int32)">
            <summary>
            Waits untill ZooKeeper connection is established
            </summary>
            <param name="connectionTimeout">
            The connection timeout.
            </param>
            <returns>
            Status
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.RetryUntilConnected``1(System.Func{``0})">
            <summary>
            Retries given delegate until connections is established
            </summary>
            <param name="callback">
            The delegate to invoke.
            </param>
            <typeparam name="T">
            Type of data returned by delegate 
            </typeparam>
            <returns>
            data returned by delegate
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Subscribe(Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperStateListener)">
            <summary>
            Subscribes listeners on ZooKeeper state changes events
            </summary>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Unsubscribe(Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperStateListener)">
            <summary>
            Un-subscribes listeners on ZooKeeper state changes events
            </summary>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Subscribe(System.String,Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperChildListener)">
            <summary>
            Subscribes listeners on ZooKeeper child changes under given path
            </summary>
            <param name="path">
            The parent path.
            </param>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Unsubscribe(System.String,Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperChildListener)">
            <summary>
            Un-subscribes listeners on ZooKeeper child changes under given path
            </summary>
            <param name="path">
            The parent path.
            </param>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Subscribe(System.String,Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperDataListener)">
            <summary>
            Subscribes listeners on ZooKeeper data changes under given path
            </summary>
            <param name="path">
            The parent path.
            </param>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Unsubscribe(System.String,Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperDataListener)">
            <summary>
            Un-subscribes listeners on ZooKeeper data changes under given path
            </summary>
            <param name="path">
            The parent path.
            </param>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.UnsubscribeAll">
            <summary>
            Un-subscribes all listeners
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.WatchForChilds(System.String)">
            <summary>
            Installs a child watch for the given path. 
            </summary>
            <param name="path">
                The parent path.
            </param>
            <returns>
            the current children of the path or null if the znode with the given path doesn't exist
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.WatchForData(System.String)">
            <summary>
            Installs a data watch for the given path. 
            </summary>
            <param name="path">
            The parent path.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Exists(System.String)">
            <summary>
            Checks whether znode for a given path exists
            </summary>
            <param name="path">
            The given path.
            </param>
            <returns>
            Result of check
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Exists(System.String,System.Boolean)">
            <summary>
            Checks whether znode for a given path exists.
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="watch">
            Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Result of check
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.GetChildren(System.String)">
            <summary>
            Gets all children for a given path
            </summary>
            <param name="path">
                The given path.
            </param>
            <returns>
            Children
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.GetChildren(System.String,System.Boolean)">
            <summary>
            Gets all children for a given path
            </summary>
            <param name="path">
                The given path.
            </param>
            <param name="watch">
                Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Children
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.CountChildren(System.String)">
            <summary>
            Counts number of children for a given path.
            </summary>
            <param name="path">
            The given path.
            </param>
            <returns>
            Number of children 
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.ReadData``1(System.String,Org.Apache.Zookeeper.Data.Stat,System.Boolean)">
            <summary>
            Fetches data from a given path in ZooKeeper
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="stats">
            The statistics.
            </param>
            <param name="watch">
            Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <typeparam name="T">
            Expected type of data
            </typeparam>
            <returns>
            Data
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.ReadData``1(System.String,Org.Apache.Zookeeper.Data.Stat)">
            <summary>
            Fetches data from a given path in ZooKeeper
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="stats">
            The statistics.
            </param>
            <typeparam name="T">
            Expected type of data
            </typeparam>
            <returns>
            Data
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.ReadData``1(System.String)">
            <summary>
            Fetches data from a given path in ZooKeeper
            </summary>
            <typeparam name="T">
            Expected type of data
            </typeparam>
            <param name="path">
            The given path.
            </param>
            <returns>
            Data or null, if znode does not exist
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.ReadData``1(System.String,System.Boolean)">
            <summary>
            Fetches data for given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="returnNullIfPathNotExists">
            Indicates, whether should return null or throw exception when 
            znode doesn't exist
            </param>
            <typeparam name="T">
            Expected type of data
            </typeparam>
            <returns>
            Data
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.WriteData(System.String,System.Object)">
            <summary>
            Writes data for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.WriteData(System.String,System.Object,System.Int32)">
            <summary>
            Writes data for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <param name="expectedVersion">
            Expected version of data
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.Delete(System.String)">
            <summary>
            Deletes znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <returns>
            Status
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.DeleteRecursive(System.String)">
            <summary>
            Deletes znode and his children for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <returns>
            Status
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.MakeSurePersistentPathExists(System.String)">
            <summary>
            Creates persistent znode and all intermediate znodes (if do not exist) for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.GetChildrenParentMayNotExist(System.String)">
            <summary>
            Fetches children for a given path
            </summary>
            <param name="path">
                The path.
            </param>
            <returns>
            Children or null, if znode does not exist
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.CreatePersistent(System.String,System.Boolean)">
            <summary>
            Creates a persistent znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="createParents">
            Indicates whether should create all intermediate znodes
            </param>
            <remarks>
            Persistent znodes won't disappear after session close
            Doesn't re-create missing intermediate znodes
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.CreatePersistent(System.String)">
            <summary>
            Creates a persistent znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <remarks>
            Persistent znodes won't disappear after session close
            Doesn't re-create missing intermediate znodes
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.CreatePersistent(System.String,System.Object)">
            <summary>
            Creates a persistent znode for a given path and writes data into it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <remarks>
            Persistent znodes won't disappear after session close
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.CreatePersistentSequential(System.String,System.Object)">
            <summary>
            Creates a sequential, persistent znode for a given path and writes data into it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <remarks>
            Persistent znodes won't dissapear after session close
            </remarks>
            <returns>
            The created znode's path
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.CreateEphemeral(System.String)">
            <summary>
            Creates a ephemeral znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <remarks>
            Ephemeral znodes will disappear after session close
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.CreateEphemeral(System.String,System.Object)">
            <summary>
            Creates a ephemeral znode for a given path and writes data into it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <remarks>
            Ephemeral znodes will disappear after session close
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperClient.CreateEphemeralSequential(System.String,System.Object)">
            <summary>
            Creates a ephemeral, sequential znode for a given path and writes data into it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <remarks>
            Ephemeral znodes will disappear after session close
            </remarks>
            <returns>
            Created znode's path
            </returns>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection">
            <summary>
            Abstracts connection with ZooKeeper server
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.ClientState">
            <summary>
            Gets the ZooKeeper client state
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.Servers">
            <summary>
            Gets the list of ZooKeeper servers.
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.SessionTimeout">
            <summary>
            Gets the ZooKeeper session timeout
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.GetInternalZKClient">
            <summary>
            Gets ZooKeeper client.
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.Connect(ZooKeeperNet.IWatcher)">
            <summary>
            Connects to ZooKeeper server
            </summary>
            <param name="watcher">
            The watcher to be installed in ZooKeeper.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.Create(System.String,System.Byte[],ZooKeeperNet.CreateMode)">
            <summary>
            Creates znode using given create mode for given path and writes given data to it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <param name="mode">
            The create mode.
            </param>
            <returns>
            The created znode's path
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.Delete(System.String)">
            <summary>
            Deletes znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.Exists(System.String,System.Boolean)">
            <summary>
            Checks whether znode for a given path exists.
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="watch">
            Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Result of check
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.GetChildren(System.String,System.Boolean)">
            <summary>
            Gets all children for a given path
            </summary>
            <param name="path">
                The given path.
            </param>
            <param name="watch">
                Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Children
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.ReadData(System.String,Org.Apache.Zookeeper.Data.Stat,System.Boolean)">
            <summary>
            Fetches data from a given path in ZooKeeper
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="stats">
            The statistics.
            </param>
            <param name="watch">
            Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Data
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.WriteData(System.String,System.Byte[])">
            <summary>
            Writes data for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.WriteData(System.String,System.Byte[],System.Int32)">
            <summary>
            Writes data for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <param name="version">
            Expected version of data
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection.GetCreateTime(System.String)">
            <summary>
            Gets time when connetion was created
            </summary>
            <param name="path">
            The path.
            </param>
            <returns>
            Connection creation time
            </returns>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.IZooKeeperSerializer">
            <summary>
            Zookeeper is able to store data in form of byte arrays. This interfacte is a bridge between those byte-array format
            and higher level objects.
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperSerializer.Serialize(System.Object)">
            <summary>
            Serializes data
            </summary>
            <param name="obj">
            The data to serialize
            </param>
            <returns>
            Serialized data
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.IZooKeeperSerializer.Deserialize(System.Byte[])">
            <summary>
            Deserializes data
            </summary>
            <param name="bytes">
            The serialized data
            </param>
            <returns>
            The deserialized data
            </returns>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Listeners.BrokerTopicsListener">
            <summary>
            Listens to new broker registrations under a particular topic, in zookeeper and
            keeps the related data structures updated
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.BrokerTopicsListener.#ctor(Kafka.Client.ZooKeeperIntegration.IZooKeeperClient,System.Collections.Generic.IDictionary{System.String,System.Collections.Generic.SortedSet{Kafka.Client.Cluster.Partition}},System.Collections.Generic.IDictionary{System.Int32,Kafka.Client.Cluster.Broker},System.Action{System.Int32,System.String,System.Int32})">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.Listeners.BrokerTopicsListener"/> class.
            </summary>
            <param name="zkclient">The wrapper on ZooKeeper client.</param>
            <param name="actualBrokerTopicsPartitionsMap">The actual broker topics partitions map.</param>
            <param name="actualBrokerIdMap">The actual broker id map.</param>
            <param name="callback">The callback invoked after new broker is added.</param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.BrokerTopicsListener.HandleChildChange(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs)">
            <summary>
            Called when the children of the given path changed
            </summary>
            <param name="e">The <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs"/> instance containing the event data
            as parent path and children (null if parent was deleted).
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.BrokerTopicsListener.ResetState">
            <summary>
            Resets the state of listener.
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.BrokerTopicsListener.ProcessNewBrokerInExistingTopic(System.String,System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Generate the updated mapping of (brokerId, numPartitions) for the new list of brokers
            registered under some topic.
            </summary>
            <param name="topic">The path of the topic under which the brokers have changed..</param>
            <param name="childs">The list of changed brokers.</param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.BrokerTopicsListener.ProcessBrokerChange(System.String,System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Processes change in the broker lists.
            </summary>
            <param name="path">The parent path of brokers list.</param>
            <param name="childs">The current brokers.</param>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperChildListener">
            <summary>
            Listener that can be registered for listening on ZooKeeper znode changes for a given path
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperChildListener.HandleChildChange(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs)">
            <summary>
            Called when the children of the given path changed
            </summary>
            <param name="args">The <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs"/> instance containing the event data
            as parent path and children (null if parent was deleted).
            </param>
            <remarks> 
            http://zookeeper.wiki.sourceforge.net/ZooKeeperWatches
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperChildListener.ResetState">
            <summary>
            Resets the state of listener.
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperDataListener">
            <summary>
            Listener that can be registered for listening on ZooKeeper znode data changes for a given path
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperDataListener.HandleDataChange(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs)">
            <summary>
            Called when the data of the given path changed
            </summary>
            <param name="args">The <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs"/> instance containing the event data
            as path and data.
            </param>
            <remarks> 
            http://zookeeper.wiki.sourceforge.net/ZooKeeperWatches
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperDataListener.HandleDataDelete(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs)">
            <summary>
            Called when the data of the given path was deleted
            </summary>
            <param name="args">The <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs"/> instance containing the event data
            as path.
            </param>
            <remarks> 
            http://zookeeper.wiki.sourceforge.net/ZooKeeperWatches
            </remarks>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperStateListener">
            <summary>
            Handles the session expiration event in ZooKeeper
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperStateListener.HandleStateChanged(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs)">
            <summary>
            Called when the ZooKeeper connection state has changed.
            </summary>
            <param name="args">The <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs"/> instance containing the event data.</param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperStateListener.HandleSessionCreated(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperSessionCreatedEventArgs)">
            <summary>
            Called after the ZooKeeper session has expired and a new session has been created.
            </summary>
            <param name="args">The <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperSessionCreatedEventArgs"/> instance containing the event data.</param>
            <remarks>
            You would have to re-create any ephemeral nodes here.
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.ZKRebalancerListener`1.HandleChildChange(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs)">
            <summary>
            Called when the children of the given path changed
            </summary>
            <param name="args">The <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs"/> instance containing the event data
            as parent path and children (null if parent was deleted).
            </param>
            <remarks> 
            http://zookeeper.wiki.sourceforge.net/ZooKeeperWatches
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.ZKRebalancerListener`1.ResetState">
            <summary>
            Resets the state of listener.
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.ZKSessionExpireListener`1.HandleStateChanged(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs)">
            <summary>
            Called when the ZooKeeper connection state has changed.
            </summary>
            <param name="args">The <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs"/> instance containing the event data.</param>
            <remarks>
            Do nothing, since zkclient will do reconnect for us.
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.Listeners.ZKSessionExpireListener`1.HandleSessionCreated(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperSessionCreatedEventArgs)">
            <summary>
            Called after the ZooKeeper session has expired and a new session has been created.
            </summary>
            <param name="args">The <see cref="T:Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperSessionCreatedEventArgs"/> instance containing the event data.</param>
            <remarks>
            You would have to re-create any ephemeral nodes here.
            Explicitly trigger load balancing for this consumer.
            </remarks>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient">
            <summary>
            Abstracts the interaction with zookeeper and allows permanent (not just one time) watches on nodes in ZooKeeper 
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.#ctor(Kafka.Client.ZooKeeperIntegration.IZooKeeperConnection,Kafka.Client.ZooKeeperIntegration.IZooKeeperSerializer,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient"/> class.
            </summary>
            <param name="connection">
            The connection to ZooKeeper.
            </param>
            <param name="serializer">
            The given serializer.
            </param>
            <param name="connectionTimeout">
            The connection timeout (in miliseconds). Default is infinitive.
            </param>
            <remarks>
            Default serializer is string UTF-8 serializer
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.#ctor(System.String,System.Int32,Kafka.Client.ZooKeeperIntegration.IZooKeeperSerializer)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient"/> class.
            </summary>
            <param name="servers">
            The list of ZooKeeper servers.
            </param>
            <param name="sessionTimeout">
            The session timeout (in miliseconds).
            </param>
            <param name="serializer">
            The given serializer.
            </param>
            <remarks>
            Default serializer is string UTF-8 serializer.
            It is recommended to use quite large sessions timeouts for ZooKeeper.
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.#ctor(System.String,System.Int32,Kafka.Client.ZooKeeperIntegration.IZooKeeperSerializer,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient"/> class.
            </summary>
            <param name="servers">
            The list of ZooKeeper servers.
            </param>
            <param name="sessionTimeout">
            The session timeout (in miliseconds).
            </param>
            <param name="serializer">
            The given serializer.
            </param>
            <param name="connectionTimeout">
            The connection timeout (in miliseconds).
            </param>
            <remarks>
            Default serializer is string UTF-8 serializer.
            It is recommended to use quite large sessions timeouts for ZooKeeper.
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Connect">
            <summary>
            Connects to ZooKeeper server within given time period and installs watcher in ZooKeeper
            </summary>
            <remarks>
            Also, starts background thread for event handling
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Disconnect">
            <summary>
            Closes current connection to ZooKeeper
            </summary>
            <remarks>
            Also, stops background thread
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Reconnect(System.String,System.Int32)">
            <summary>
            Re-connect to ZooKeeper server when session expired
            </summary>
            <param name="servers">
            The servers.
            </param>
            <param name="connectionTimeout">
            The connection timeout.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.WaitUntilConnected(System.Int32)">
            <summary>
            Waits untill ZooKeeper connection is established
            </summary>
            <param name="connectionTimeout">
            The connection timeout.
            </param>
            <returns>
            Status
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.RetryUntilConnected``1(System.Func{``0})">
            <summary>
            Retries given delegate until connections is established
            </summary>
            <param name="callback">
            The delegate to invoke.
            </param>
            <typeparam name="T">
            Type of data returned by delegate 
            </typeparam>
            <returns>
            data returned by delegate
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.RetryUntilConnected``1(System.Func{``0},System.TimeSpan)">
            <summary>
            Retries given delegate until connections is established
            </summary>
            <param name="callback">
            The delegate to invoke.
            </param>
            <param name="timeout"></param>
            <typeparam name="T">
            Type of data returned by delegate 
            </typeparam>
            <returns>
            data returned by delegate
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Exists(System.String)">
            <summary>
            Checks whether znode for a given path exists
            </summary>
            <param name="path">
            The given path.
            </param>
            <returns>
            Result of check
            </returns>
            <remarks>
            Will reinstall watcher in ZooKeeper if any listener for given path exists 
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Exists(System.String,System.Boolean)">
            <summary>
            Checks whether znode for a given path exists.
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="watch">
            Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Result of check
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.GetChildren(System.String)">
            <summary>
            Gets all children for a given path
            </summary>
            <param name="path">
                The given path.
            </param>
            <returns>
            Children
            </returns>
            <remarks>
            Will reinstall watcher in ZooKeeper if any listener for given path exists 
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.GetChildren(System.String,System.Boolean)">
            <summary>
            Gets all children for a given path
            </summary>
            <param name="path">
                The given path.
            </param>
            <param name="watch">
                Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Children
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.CountChildren(System.String)">
            <summary>
            Counts number of children for a given path.
            </summary>
            <param name="path">
            The given path.
            </param>
            <returns>
            Number of children 
            </returns>
            <remarks>
            Will reinstall watcher in ZooKeeper if any listener for given path exists.
            Returns 0 if path does not exist
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ReadData``1(System.String,Org.Apache.Zookeeper.Data.Stat,System.Boolean)">
            <summary>
            Fetches data from a given path in ZooKeeper
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="stats">
            The statistics.
            </param>
            <param name="watch">
            Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <typeparam name="T">
            Expected type of data
            </typeparam>
            <returns>
            Data
            </returns>
            <remarks>
            Uses given serializer to deserialize data
            Use null for stats
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ReadData``1(System.String,Org.Apache.Zookeeper.Data.Stat)">
            <summary>
            Fetches data from a given path in ZooKeeper
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="stats">
            The statistics.
            </param>
            <typeparam name="T">
            Expected type of data
            </typeparam>
            <returns>
            Data
            </returns>
            <remarks>
            Uses given serializer to deserialize data.
            Will reinstall watcher in ZooKeeper if any listener for given path exists.
            Use null for stats
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.WriteData(System.String,System.Object)">
            <summary>
            Writes data for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.WriteData(System.String,System.Object,System.Int32)">
            <summary>
            Writes data for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <param name="expectedVersion">
            Expected version of data
            </param>
            <remarks>
            Use -1 for expected version
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Delete(System.String)">
            <summary>
            Deletes znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <returns>
            Status
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.DeleteRecursive(System.String)">
            <summary>
            Deletes znode and his children for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <returns>
            Status
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.MakeSurePersistentPathExists(System.String)">
            <summary>
            Creates persistent znode and all intermediate znodes (if do not exist) for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.GetChildrenParentMayNotExist(System.String)">
            <summary>
            Fetches children for a given path
            </summary>
            <param name="path">
                The path.
            </param>
            <returns>
            Children or null, if znode does not exist
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ReadData``1(System.String)">
            <summary>
            Fetches data from a given path in ZooKeeper
            </summary>
            <typeparam name="T">
            Expected type of data
            </typeparam>
            <param name="path">
            The given path.
            </param>
            <returns>
            Data or null, if znode does not exist
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Dispose">
            <summary>
            Closes connection to ZooKeeper
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.CreatePersistent(System.String,System.Boolean)">
            <summary>
            Creates a persistent znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="createParents">
            Indicates, whether should create missing intermediate znodes
            </param>
            <remarks>
            Persistent znodes won't disappear after session close
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.CreatePersistent(System.String)">
            <summary>
            Creates a persistent znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <remarks>
            Persistent znodes won't disappear after session close
            Doesn't re-create missing intermediate znodes
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.CreatePersistent(System.String,System.Object)">
            <summary>
            Creates a persistent znode for a given path and writes data into it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <remarks>
            Persistent znodes won't disappear after session close
            Doesn't re-create missing intermediate znodes
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.CreatePersistentSequential(System.String,System.Object)">
            <summary>
            Creates a sequential, persistent znode for a given path and writes data into it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <remarks>
            Persistent znodes won't disappear after session close
            Doesn't re-create missing intermediate znodes
            </remarks>
            <returns>
            The created znode's path
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Create(System.String,System.Object,ZooKeeperNet.CreateMode)">
            <summary>
            Helper method to create znode
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <param name="mode">
            The create mode.
            </param>
            <returns>
            The created znode's path
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.CreateEphemeral(System.String)">
            <summary>
            Creates a ephemeral znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <remarks>
            Ephemeral znodes will disappear after session close
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.CreateEphemeral(System.String,System.Object)">
            <summary>
            Creates a ephemeral znode for a given path and writes data into it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <remarks>
            Ephemeral znodes will disappear after session close
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.CreateEphemeralSequential(System.String,System.Object)">
            <summary>
            Creates a ephemeral, sequential znode for a given path and writes data into it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <remarks>
            Ephemeral znodes will disappear after session close
            </remarks>
            <returns>
            Created znode's path
            </returns>
        </member>
        <!-- Badly formed XML comment ignored for member "M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ReadData``1(System.String,System.Boolean)" -->
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.EnsuresNotDisposed">
            <summary>
            Ensures that object wasn't disposed
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ZooKeeperEventHandler`1">
            <summary>
            Represents the method that will handle a ZooKeeper event  
            </summary>
            <param name="args">
            The args.
            </param>
            <typeparam name="T">
            Type of event data
            </typeparam>
        </member>
        <member name="E:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.StateChanged">
            <summary>
            Occurs when ZooKeeper connection state changes
            </summary>
        </member>
        <member name="E:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.SessionCreated">
            <summary>
            Occurs when ZooKeeper session re-creates
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.IdleTime">
            <summary>
            Gets time (in miliseconds) of event thread iddleness
            </summary>
            <remarks>
            Used for testing purpose
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Subscribe(Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperStateListener)">
            <summary>
            Subscribes listeners on ZooKeeper state changes events
            </summary>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Unsubscribe(Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperStateListener)">
            <summary>
            Un-subscribes listeners on ZooKeeper state changes events
            </summary>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Subscribe(System.String,Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperChildListener)">
            <summary>
            Subscribes listeners on ZooKeeper child changes under given path
            </summary>
            <param name="path">
            The parent path.
            </param>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Unsubscribe(System.String,Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperChildListener)">
            <summary>
            Un-subscribes listeners on ZooKeeper child changes under given path
            </summary>
            <param name="path">
            The parent path.
            </param>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Subscribe(System.String,Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperDataListener)">
            <summary>
            Subscribes listeners on ZooKeeper data changes under given path
            </summary>
            <param name="path">
            The parent path.
            </param>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Unsubscribe(System.String,Kafka.Client.ZooKeeperIntegration.Listeners.IZooKeeperDataListener)">
            <summary>
            Un-subscribes listeners on ZooKeeper data changes under given path
            </summary>
            <param name="path">
            The parent path.
            </param>
            <param name="listener">
            The listener.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.UnsubscribeAll">
            <summary>
            Un-subscribes all listeners
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.WatchForChilds(System.String)">
            <summary>
            Installs a child watch for the given path. 
            </summary>
            <param name="path">
                The parent path.
            </param>
            <returns>
            the current children of the path or null if the znode with the given path doesn't exist
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.WatchForData(System.String)">
            <summary>
            Installs a data watch for the given path. 
            </summary>
            <param name="path">
            The parent path.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.HasListeners(System.String)">
            <summary>
            Checks whether any data or child listeners are registered
            </summary>
            <param name="path">
            The path.
            </param>
            <returns>
            Value indicates whether any data or child listeners are registered
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.RunEventWorker">
            <summary>
            Event thread starting method
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.PoolEventsQueue">
            <summary>
            Pools ZooKeeper events form events queue
            </summary>
            <remarks>
            Thread sleeps if queue is empty
            </remarks>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Enqueue(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperEventArgs)">
            <summary>
            Enqueues new event from ZooKeeper in events queue
            </summary>
            <param name="e">
            The event from ZooKeeper.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.Dequeue">
            <summary>
            Dequeues event from events queue and invokes subscribed handlers
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ProcessStateChange(ZooKeeperNet.WatchedEvent)">
            <summary>
            Processess ZooKeeper state changes events
            </summary>
            <param name="e">
            The event data.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.ProcessDataOrChildChange(ZooKeeperNet.WatchedEvent)">
            <summary>
            Processess ZooKeeper childs or data changes events
            </summary>
            <param name="e">
            The event data.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.OnStateChanged(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperStateChangedEventArgs)">
            <summary>
            Invokes subscribed handlers for ZooKeeeper state changes event
            </summary>
            <param name="e">
            The event data
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.OnSessionCreated(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperSessionCreatedEventArgs)">
            <summary>
            Invokes subscribed handlers for ZooKeeeper session re-creates event
            </summary>
            <param name="e">
            The event data.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.OnChildChanged(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperChildChangedEventArgs)">
            <summary>
            Invokes subscribed handlers for ZooKeeeper child changes event
            </summary>
            <param name="e">
            The event data.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperClient.OnDataChanged(Kafka.Client.ZooKeeperIntegration.Events.ZooKeeperDataChangedEventArgs)">
            <summary>
            Invokes subscribed handlers for ZooKeeeper data changes event
            </summary>
            <param name="e">
            The event data.
            </param>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection">
            <summary>
            Abstracts connection with ZooKeeper server
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection"/> class.
            </summary>
            <param name="servers">
            The list of ZooKeeper servers.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.#ctor(System.String,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection"/> class.
            </summary>
            <param name="servers">
            The list of ZooKeeper servers.
            </param>
            <param name="sessionTimeout">
            The session timeout.
            </param>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.Servers">
            <summary>
            Gets the list of ZooKeeper servers.
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.SessionTimeout">
            <summary>
            Gets the ZooKeeper session timeout
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.GetInternalZKClient">
            <summary>
            Gets ZooKeeper client.
            </summary>
        </member>
        <member name="P:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.ClientState">
            <summary>
            Gets the ZooKeeper client state
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.Connect(ZooKeeperNet.IWatcher)">
            <summary>
            Connects to ZooKeeper server
            </summary>
            <param name="watcher">
            The watcher to be installed in ZooKeeper.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.Delete(System.String)">
            <summary>
            Deletes znode for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.Exists(System.String,System.Boolean)">
            <summary>
            Checks whether znode for a given path exists.
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="watch">
            Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Result of check
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.Create(System.String,System.Byte[],ZooKeeperNet.CreateMode)">
            <summary>
            Creates znode using given create mode for given path and writes given data to it
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <param name="mode">
            The create mode.
            </param>
            <returns>
            The created znode's path
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.GetChildren(System.String,System.Boolean)">
            <summary>
            Gets all children for a given path
            </summary>
            <param name="path">
                The given path.
            </param>
            <param name="watch">
                Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Children
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.ReadData(System.String,Org.Apache.Zookeeper.Data.Stat,System.Boolean)">
            <summary>
            Fetches data from a given path in ZooKeeper
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="stats">
            The statistics.
            </param>
            <param name="watch">
            Indicates whether should reinstall watcher in ZooKeeper.
            </param>
            <returns>
            Data
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.WriteData(System.String,System.Byte[])">
            <summary>
            Writes data for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.WriteData(System.String,System.Byte[],System.Int32)">
            <summary>
            Writes data for a given path
            </summary>
            <param name="path">
            The given path.
            </param>
            <param name="data">
            The data to write.
            </param>
            <param name="version">
            Expected version of data
            </param>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.GetCreateTime(System.String)">
            <summary>
            Gets time when connetion was created
            </summary>
            <param name="path">
            The path.
            </param>
            <returns>
            Connection creation time
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.Dispose">
            <summary>
            Closes underlying ZooKeeper client
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperConnection.EnsuresNotDisposedAndNotNull">
            <summary>
            Ensures object wasn't disposed
            </summary>
        </member>
        <member name="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperStringSerializer">
            <summary>
            Zookeeper is able to store data in form of byte arrays. This interfacte is a bridge between those byte-array format
            and higher level objects.
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperStringSerializer.#ctor">
            <summary>
            Prevents a default instance of the <see cref="T:Kafka.Client.ZooKeeperIntegration.ZooKeeperStringSerializer"/> class from being created.
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperStringSerializer.Serialize(System.Object)">
            <summary>
            Serializes data using UTF-8 encoding
            </summary>
            <param name="obj">
            The data to serialize
            </param>
            <returns>
            Serialized data
            </returns>
        </member>
        <member name="M:Kafka.Client.ZooKeeperIntegration.ZooKeeperStringSerializer.Deserialize(System.Byte[])">
            <summary>
            Deserializes data using UTF-8 encoding
            </summary>
            <param name="bytes">
            The serialized data
            </param>
            <returns>
            The deserialized data
            </returns>
        </member>
        <member name="T:Kafka.Client.Cluster.Cluster">
            <summary>
            The set of active brokers in the cluster
            </summary>
        </member>
        <member name="M:Kafka.Client.Cluster.Cluster.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Cluster.Cluster"/> class.
            </summary>
        </member>
        <member name="M:Kafka.Client.Cluster.Cluster.#ctor(Kafka.Client.ZooKeeperIntegration.IZooKeeperClient)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Cluster.Cluster"/> class.
            </summary>
            <param name="zkClient">IZooKeeperClient object</param>
        </member>
        <member name="M:Kafka.Client.Cluster.Cluster.#ctor(System.Collections.Generic.IEnumerable{Kafka.Client.Cluster.Broker})">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Cluster.Cluster"/> class.
            </summary>
            <param name="brokers">
            The set of active brokers.
            </param>
        </member>
        <member name="M:Kafka.Client.Cluster.Cluster.GetBroker(System.Int32)">
            <summary>
            Gets broker with given ID
            </summary>
            <param name="id">
            The broker ID.
            </param>
            <returns>
            The broker with given ID
            </returns>
        </member>
        <member name="P:Kafka.Client.Cluster.Cluster.Brokers">
            <summary>
            Gets brokers collection
            </summary>
        </member>
        <member name="M:Kafka.Client.Cluster.Cluster.CreateBroker(System.String,System.String)">
            <summary>
            Creates a new Broker object out of a BrokerInfoString
            </summary>
            <param name="node">node string</param>
            <param name="brokerInfoString">the BrokerInfoString</param>
            <returns>Broker object</returns>
        </member>
        <member name="T:Kafka.Client.Cluster.Partition">
            <summary>
            Represents broker partition
            </summary>
        </member>
        <member name="P:Kafka.Client.Cluster.Partition.PartId">
            <summary>
            Gets the partition ID.
            </summary>
        </member>
        <member name="T:Kafka.Client.Cluster.Broker">
            <summary>
            Represents Kafka broker
            </summary>
        </member>
        <member name="M:Kafka.Client.Cluster.Broker.#ctor(System.Int32,System.String,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Cluster.Broker"/> class.
            </summary>
            <param name="id">
            The broker id.
            </param>
            <param name="host">
            The broker host.
            </param>
            <param name="port">
            The broker port.
            </param>
        </member>
        <member name="P:Kafka.Client.Cluster.Broker.Id">
            <summary>
            Gets the broker Id.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cluster.Broker.Host">
            <summary>
            Gets the broker host.
            </summary>
        </member>
        <member name="P:Kafka.Client.Cluster.Broker.Port">
            <summary>
            Gets the broker port.
            </summary>
        </member>
        <member name="M:Kafka.Client.ExceptionExtensions.FormatException(System.Exception)">
            <summary>
                Formats an exception object into a printable string.
            </summary>
            <param name="exception">the exception to format</param>
            <returns>a string</returns>
        </member>
        <member name="T:Kafka.Client.Exceptions.BrokerNotAvailableException">
            <summary>
            The exception that is thrown when broker information is not available on ZooKeeper server
            </summary>
        </member>
        <member name="T:Kafka.Client.Exceptions.NoPartitionsForTopicException">
            <summary>
            The exception that is thrown when no partitions found for specified topic
            </summary>
        </member>
        <member name="T:Kafka.Client.Exceptions.OffsetIsUnknowException">
            <summary>
            The exception that is thrown when could not retrieve offset from broker for specific partition of specific topic
            </summary>
        </member>
        <member name="T:Kafka.Client.Exceptions.KafkaException">
            <summary>
            A wrapping of an error code returned from Kafka.
            </summary>
        </member>
        <member name="M:Kafka.Client.Exceptions.KafkaException.#ctor(System.Int16)">
            <summary>
            Initializes a new instance of the KafkaException class.
            </summary>
            <param name="errorCode">The error code generated by a request to Kafka.</param>
        </member>
        <member name="P:Kafka.Client.Exceptions.KafkaException.ErrorCode">
            <summary>
            Gets the error code that was sent from Kafka.
            </summary>
        </member>
        <member name="M:Kafka.Client.Exceptions.KafkaException.GetMessage(System.Int16)">
            <summary>
            Gets the message for the exception based on the Kafka error code.
            </summary>
            <param name="errorCode">The error code from Kafka.</param>
            <returns>A string message representation </returns>
        </member>
        <member name="T:Kafka.Client.Helper.KafkaSimpleManager`2">
             <summary>
             Manage :
                 syncProducerPool to get metadta/offset
                 ProducerPool to send.
                 ConsumerPool to consume.
                 
                 new KafkaSimpleManager()
                 Scenario 1:  
                     RefreshMetadata()
                     RefreshAndGetOffsetByTimeStamp()
             
             
                 Scenario 2 Produce :
                 
                     Sub scenario 1:  Send to random partition
                     Sub scenario 2:  Send to specific partition
                     For Sub scenario 1 and 2:
                         InitializeProducerPoolForTopic        
                         call GetProducer() to get required producer
                             Send 
                             If send failed, call  RefreshMetadataAndRecreateProducerWithPartition
                     
             
                     Sub scenario 3:  Send to partition by default partitioner class.   Math.Abs(key.GetHashCode()) % numPartitions
                     Sub scenario 4:  Send to partition by customized partitioner
                     For Sub scenario 3 and 4:
                         InitializeProducerPoolForTopic
                         call GetProducerWithPartionerClass() to get producer
                             Send
                             If send failed, call RefreshMetadata and retry.
            
                 Scenario 3 Consume pool:
                     call GetConsumerFromPool() to get consumer
                         consume
                         If consume failed, call  GetConsumerFromPoolAfterRecreate() to get new consumer.
                     
             
             </summary>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.RecreateSyncProducerPoolForMetadata">
            <summary>
            Initialize SyncProducerPool used for get metadata by query Zookeeper
            Here only build connection for all ACTIVE broker.  So client actually need regularly dispose/recreate or refresh, for example, every 20 minutes..
            </summary>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.ClearSyncProducerPoolForMetadata">
            <summary>
            Reset syncProducer pool
            </summary>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.RefreshMetadata(System.Int16,System.String,System.Int32,System.String,System.Boolean)">
            <summary>
            Refresh metadata of one topic and return.
            If can't get metadata for specified topic at first time, will RecreateSyncProducerPoolForMetadata and retry once.
            MANIFOLD use.
            </summary>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.GetLeaderBrokerOfPartition(System.String,System.Int32)">
            <summary>
            Get leader broker of one topic partition. without retry.
            If got exception from this, probably need client code call RefreshMetadata with force = true.
            </summary>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.RefreshAndGetOffset(System.Int16,System.String,System.Int32,System.String,System.Int32,System.Boolean,System.Int64@,System.Int64@)">
            <summary>
             Get offset
            </summary>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.GetProducerWithPartionerClass(System.String)">
            <summary>
            Get Producer once Config.PartitionerClass is one valid class full name.
            </summary>
            <param name="topic"></param>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.GetProducerOfPartition(System.String,System.Int32,System.Boolean)">
            <summary>
            Get Producer once  Config.PartitionerClass is null or empty.
            </summary>
            <param name="topic"></param>
            <param name="partitionID"></param>
            <param name="randomReturnIfProducerOfTargetPartionNotExists"></param>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.GetConsumer(System.String,System.Int32)">
            <summary>
            Get Consumer object from current cached metadata information without retry.
            So maybe got exception if the related metadata not exists.
            When create ConsumerConfiguration, will take BufferSize and FetchSize from KafkaSimpleManagerConfiguration
            Client side need handle exception and the metadata change 
            </summary>
            <param name="topic"></param>
            <param name="partitionID"></param>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.GetConsumer(System.String,System.Int32,Kafka.Client.Cfg.ConsumerConfiguration)">
            <summary>
            Get Consumer object from current cached metadata information without retry.
            So maybe got exception if the related metadata not exists.
            When create ConsumerConfiguration, will take values in cosumerConfigTemplate.
            Client side need handle exception and the metadata change 
            </summary>
            <param name="topic"></param>
            <param name="partitionID"></param>
            <param name="cosumerConfigTemplate"></param>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.GetConsumerFromPool(System.Int16,System.String,System.Int32,System.String,Kafka.Client.Cfg.ConsumerConfiguration,System.Int32)">
            <summary>
            MANIFOLD use .  get one consumer from the pool.
            </summary>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.GetConsumerFromPoolAfterRecreate(System.Int16,System.String,System.Int32,System.String,Kafka.Client.Cfg.ConsumerConfiguration,System.Int32,System.Int32)">
            <summary>
            MANIFOLD use .  Force recreate consumer for some partition and return it back.
            </summary>
        </member>
        <member name="M:Kafka.Client.Helper.KafkaSimpleManager`2.Dispose">
            <summary>
            Implement IDisposable
            </summary>
        </member>
        <member name="T:Kafka.Client.KafkaConnection">
            <summary>
            Manages connections to the Kafka.
            </summary>
        </member>
        <member name="M:Kafka.Client.KafkaConnection.#ctor(System.String,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the KafkaConnection class.
            </summary>
            <param name="server">The server to connect to.</param>
            <param name="port">The port to connect to.</param>
            <param name="bufferSize"></param>
            <param name="sendTimeoutMs"></param>
            <param name="receiveTimeoutMs"></param>
            <param name="reconnectIntervalMs"></param>
        </member>
        <member name="M:Kafka.Client.KafkaConnection.Send(Kafka.Client.Requests.ProducerRequest)">
            <summary>
            Writes a producer request to the server.
            </summary>
            <remarks>
            Write timeout is defaulted to infitite.
            </remarks>
            <param name="request">The <see cref="T:Kafka.Client.Requests.ProducerRequest"/> to send to the server.</param>
        </member>
        <member name="M:Kafka.Client.KafkaConnection.Send(Kafka.Client.Requests.TopicMetadataRequest)">
            <summary>
            Writes a topic metadata request to the server.
            </summary>
            <remarks>
            Write timeout is defaulted to infitite.
            </remarks>
            <param name="request">The <see cref="T:Kafka.Client.Requests.TopicMetadataRequest"/> to send to the server.</param>
        </member>
        <member name="M:Kafka.Client.KafkaConnection.Send(Kafka.Client.Requests.FetchRequest)">
            <summary>
            Writes a fetch request to the server.
            </summary>
            <remarks>
            Write timeout is defaulted to infitite.
            </remarks>
            <param name="request">The <see cref="T:Kafka.Client.Requests.FetchRequest"/> to send to the server.</param>
        </member>
        <member name="M:Kafka.Client.KafkaConnection.Send(Kafka.Client.Requests.OffsetRequest)">
            <summary>
            Writes a offset request to the server.
            </summary>
            <remarks>
            Write timeout is defaulted to infitite.
            </remarks>
            <param name="request">The <see cref="T:Kafka.Client.Requests.OffsetRequest"/> to send to the server.</param>
        </member>
        <member name="M:Kafka.Client.KafkaConnection.Dispose">
            <summary>
            Close the connection to the server.
            </summary>
        </member>
        <member name="M:Kafka.Client.KafkaConnection.EnsuresNotDisposed">
            <summary>
            Ensures that object was not disposed
            </summary>
        </member>
        <member name="M:Kafka.Client.KafkaConnection.Send(System.Byte[])">
            <summary>
            Writes data to the server.
            </summary>
            <param name="data">The data to write to the server.</param>
        </member>
        <member name="T:Kafka.Client.Messages.BoundedBuffer">
            <summary>
            Wrapper over memory set with fixed capacity
            </summary>
        </member>
        <member name="M:Kafka.Client.Messages.BoundedBuffer.#ctor(System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Messages.BoundedBuffer"/> class.
            </summary>
            <param name="size">
            The max size of stream.
            </param>
        </member>
        <member name="T:Kafka.Client.Messages.MessageSet">
            <summary>
            A set of messages. A message set has a fixed serialized form, though the container
            for the bytes could be either in-memory or on disk.
            </summary>
            <remarks>
            Format:
            8 byte long offset
            4 byte size containing an integer N
            N message bytes as described in the message class
            </remarks>
        </member>
        <member name="M:Kafka.Client.Messages.MessageSet.GetEntrySize(Kafka.Client.Messages.Message)">
            <summary>
            Gives the size of a size-delimited entry in a message set
            </summary>
            <param name="message">
            The message.
            </param>
            <returns>
            Size of message
            </returns>
        </member>
        <member name="M:Kafka.Client.Messages.MessageSet.GetMessageSetSize(System.Collections.Generic.IEnumerable{Kafka.Client.Messages.Message})">
            <summary>
            Gives the size of a list of messages
            </summary>
            <param name="messages">
            The messages.
            </param>
            <returns>
            Size of all messages
            </returns>
        </member>
        <member name="P:Kafka.Client.Messages.MessageSet.SetSize">
            <summary>
            Gets the total size of this message set in bytes
            </summary>
        </member>
        <member name="M:Kafka.Client.Messages.MessageSet.WriteTo(System.IO.MemoryStream)">
            <summary>
            Writes content into given stream
            </summary>
            <param name="output">
            The output stream.
            </param>
        </member>
        <member name="M:Kafka.Client.Messages.MessageSet.WriteTo(Kafka.Client.Serialization.KafkaBinaryWriter)">
            <summary>
            Writes content into given writer
            </summary>
            <param name="writer">
            The writer.
            </param>
        </member>
        <member name="T:Kafka.Client.Messages.BufferedMessageSet">
            <summary>
            A collection of messages stored as memory stream
            </summary>
        </member>
        <member name="M:Kafka.Client.Messages.BufferedMessageSet.#ctor(System.Collections.Generic.IEnumerable{Kafka.Client.Messages.Message},System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Messages.BufferedMessageSet"/> class.
            </summary>
            <param name="messages">The list of messages.</param>
        </member>
        <member name="M:Kafka.Client.Messages.BufferedMessageSet.#ctor(System.Collections.Generic.IEnumerable{Kafka.Client.Messages.Message},System.Int16,System.Int64,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Messages.BufferedMessageSet"/> class.
            </summary>
            <param name="messages">
            The list of messages.
            </param>
            <param name="errorCode">
            The error code.
            </param>
        </member>
        <member name="M:Kafka.Client.Messages.BufferedMessageSet.#ctor(Kafka.Client.Messages.CompressionCodecs,System.Collections.Generic.IEnumerable{Kafka.Client.Messages.Message},System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Messages.BufferedMessageSet"/> class with compression.
            </summary>
            <param name="compressionCodec"></param>
            <param name="messages">messages to add</param>
        </member>
        <member name="P:Kafka.Client.Messages.BufferedMessageSet.ErrorCode">
            <summary>
            Gets the error code
            </summary>
        </member>
        <member name="P:Kafka.Client.Messages.BufferedMessageSet.HighwaterOffset">
            <summary>
            Gets or sets the offset marking the end of this partition log.
            </summary>
        </member>
        <member name="P:Kafka.Client.Messages.BufferedMessageSet.Messages">
            <summary>
            Gets the list of messages.
            </summary>
        </member>
        <member name="P:Kafka.Client.Messages.BufferedMessageSet.SetSize">
            <summary>
            Gets the total set size.
            </summary>
        </member>
        <member name="M:Kafka.Client.Messages.BufferedMessageSet.WriteTo(System.IO.MemoryStream)">
            <summary>
            Writes content into given stream
            </summary>
            <param name="output">
            The output stream.
            </param>
        </member>
        <member name="M:Kafka.Client.Messages.BufferedMessageSet.WriteTo(Kafka.Client.Serialization.KafkaBinaryWriter)">
            <summary>
            Writes content into given writer
            </summary>
            <param name="writer">
            The writer.
            </param>
        </member>
        <member name="M:Kafka.Client.Messages.BufferedMessageSet.ToString">
            <summary>
            Gets string representation of set
            </summary>
            <returns>
            String representation of set
            </returns>
        </member>
        <member name="T:Kafka.Client.Messages.Message">
            <summary>
            Message send to Kafka server
            </summary>
            <remarks>
            Format:
            1 byte "magic" identifier to allow format changes
            4 byte CRC32 of the payload
            N - 5 byte payload
            </remarks>
        </member>
        <member name="F:Kafka.Client.Messages.Message.MagicValueWhenCompress">
            <summary>
            Need set magic to 1 while compress,
            See https://cwiki.apache.org/confluence/display/KAFKA/Wire+Format for detail
            </summary>
        </member>
        <member name="M:Kafka.Client.Messages.Message.#ctor(System.Byte[])">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Messages.Message"/> class.
            </summary>
            <param name="payload">
            The payload.
            </param>
            <remarks>
            Initializes the magic number as default and the checksum as null. It will be automatically computed.
            </remarks>
        </member>
        <member name="M:Kafka.Client.Messages.Message.#ctor(System.Byte[],System.Byte[],Kafka.Client.Messages.CompressionCodecs)">
            <summary>
            Initializes a new instance of the Message class.
            </summary>
            <param name="payload">The data for the payload.</param>
            <param name="magic">The magic identifier.</param>
            <param name="checksum">The checksum for the payload.</param>
        </member>
        <member name="P:Kafka.Client.Messages.Message.Payload">
            <summary>
            Gets the payload.
            </summary>
        </member>
        <member name="P:Kafka.Client.Messages.Message.Magic">
            <summary>
            Gets the magic bytes.
            </summary>
        </member>
        <member name="P:Kafka.Client.Messages.Message.Attributes">
            <summary>
            Gets the Attributes for the message.
            </summary>
        </member>
        <member name="P:Kafka.Client.Messages.Message.Size">
            <summary>
            Gets the total size of message.
            </summary>
        </member>
        <member name="P:Kafka.Client.Messages.Message.PartitionId">
            <summary>
            When produce data, do not need set this field.
            When consume data, need set this field.
            </summary>
        </member>
        <member name="P:Kafka.Client.Messages.Message.PayloadSize">
            <summary>
            Gets the payload size.
            </summary>
        </member>
        <member name="M:Kafka.Client.Messages.Message.WriteTo(System.IO.MemoryStream)">
            <summary>
            Writes message data into given message buffer
            </summary>
            <param name="output">
            The output.
            </param>
        </member>
        <member name="M:Kafka.Client.Messages.Message.WriteTo(Kafka.Client.Serialization.KafkaBinaryWriter)">
            <summary>
            Writes message data using given writer
            </summary>
            <param name="writer">
                The writer.
            </param>
            <param name="getBuffer"></param>
        </member>
        <member name="M:Kafka.Client.Messages.Message.ToString">
            <summary>
            Try to show the payload as decoded to UTF-8.
            </summary>
            <returns>The decoded payload as string.</returns>
        </member>
        <member name="M:Kafka.Client.Messages.Message.ParseFrom(Kafka.Client.Serialization.KafkaBinaryReader,System.Int64,System.Int32,System.Int32)">
             A message. The format of an N byte message is the following:
            
             1. 4 byte CRC32 of the message
             2. 1 byte "magic" identifier to allow format changes, value is 2 currently
             3. 1 byte "attributes" identifier to allow annotations on the message independent of the version (e.g. compression enabled, type of codec used)
             4. 4 byte key length, containing length K
             5. K byte key
             6. 4 byte payload length, containing length V
             7. V byte payload
            
        </member>
        <member name="M:Kafka.Client.Messages.Message.CleanMagicAndAttributesBeforeCompress">
            <summary>
            Clean up attributes for message, otherwise there is double decompress at kafka broker side.
            </summary>
        </member>
        <member name="M:Kafka.Client.Messages.Message.RestoreMagicAndAttributesAfterCompress(System.Byte,System.Byte)">
            <summary>
            Restore the Magic and Attributes after compress.
            </summary>
            <param name="magic"></param>
            <param name="attributes"></param>
        </member>
        <member name="M:Kafka.Client.Producers.DefaultCallbackHandler`2.Send(System.Int32,System.Collections.Generic.IDictionary{Kafka.Client.Responses.TopicAndPartition,Kafka.Client.Messages.BufferedMessageSet})">
            <summary>
            Send message of one broker.
            </summary>
            <param name="brokerId"></param>
            <param name="messagesPerTopic"></param>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Producers.DefaultCallbackHandler`2.PartitionAndCollate(System.Collections.Generic.IEnumerable{Kafka.Client.Producers.ProducerData{`0,Kafka.Client.Messages.Message}})">
            <summary>
            Given the message to be pushed, return the partition selected, the broker leader for the partition
            </summary>
            <param name="events">message set to be produced</param>
            <returns>the partition selected and the broker leader</returns>
        </member>
        <member name="M:Kafka.Client.Producers.DefaultCallbackHandler`2.GetPartitionListForTopic(Kafka.Client.Producers.ProducerData{`0,Kafka.Client.Messages.Message})">
            <summary>
            When TotalNumPartitions is not specified in ProducerConf, it retrieves a set of partitions from the broker; 
            otherwise, returns only the partition determined by ProducerData.Key
            </summary>
            <param name="pd">ProducerData to be produced</param>
            <returns>a list of partitions for the target topic</returns>
        </member>
        <member name="T:Kafka.Client.Producers.ICallbackHandler`2">
            <summary>
            Performs action when a producer request is finished being sent asynchronously.
            </summary>
        </member>
        <member name="M:Kafka.Client.Producers.ICallbackHandler`2.Handle(System.Collections.Generic.IEnumerable{Kafka.Client.Producers.ProducerData{`0,`1}})">
            <summary>
            Performs action when a producer request is finished being sent asynchronously.
            </summary>
            <param name="events">
            The sent request events.
            </param>
        </member>
        <member name="T:Kafka.Client.Producers.PartitionData">
            <summary>
            PartitionData, contains buffered messageset
            </summary>
        </member>
        <member name="M:Kafka.Client.Producers.Partitioning.BrokerPartitionInfo.GetBrokerPartitionInfo(System.Int16,System.String,System.Int32,System.String)">
            <summary>
            Return leader of each partition.
            </summary>
            <param name="versionId"></param>
            <param name="clientId"></param>
            <param name="correlationId"></param>
            <param name="topic"></param>
            <returns></returns>
        </member>
        <member name="M:Kafka.Client.Producers.Partitioning.BrokerPartitionInfo.UpdateInfo(System.Int16,System.Int32,System.String,System.String)">
            <summary>
            Force get topic metadata and update 
            </summary>
        </member>
        <member name="T:Kafka.Client.Producers.Partitioning.DefaultPartitioner`1">
            <summary>
            Default partitioner using hash code to calculate partition
            </summary>
            <typeparam name="TKey">The type of the key.</typeparam>
        </member>
        <member name="M:Kafka.Client.Producers.Partitioning.DefaultPartitioner`1.Partition(`0,System.Int32)">
            <summary>
            Uses the key to calculate a partition bucket id for routing
            the data to the appropriate broker partition
            </summary>
            <param name="key">The key.</param>
            <param name="numPartitions">The num partitions.</param>
            <returns>ID between 0 and numPartitions-1</returns>
            <remarks>
            Uses hash code to calculate partition
            </remarks>
        </member>
        <member name="T:Kafka.Client.Producers.Partitioning.IBrokerPartitionInfo">
            <summary>
            Retrieves brokers and partitions info
            </summary>
        </member>
        <member name="T:Kafka.Client.Producers.Partitioning.IPartitioner`1">
            <summary>
            User-defined partitioner
            </summary>
            <typeparam name="TKey">The type of the key.</typeparam>
        </member>
        <member name="M:Kafka.Client.Producers.Partitioning.IPartitioner`1.Partition(`0,System.Int32)">
            <summary>
            Uses the key to calculate a partition bucket id for routing
            the data to the appropriate broker partition
            </summary>
            <param name="key">The key.</param>
            <param name="numPartitions">The num partitions.</param>
            <returns>ID between 0 and numPartitions-1</returns>
        </member>
        <member name="T:Kafka.Client.Producers.PartitionMetadata">
            <summary>
            TODO: Update summary.
            </summary>
        </member>
        <member name="T:Kafka.Client.Producers.Producer">
            <summary>
            High-level Producer API that exposes all the producer functionality to the client 
            using <see cref="T:System.String" /> as type of key and <see cref="T:Kafka.Client.Messages.Message" /> as type of data
            </summary>
        </member>
        <member name="M:Kafka.Client.Producers.Producer.#ctor(Kafka.Client.Cfg.ProducerConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Producers.Producer"/> class.
            </summary>
            <param name="config">The config object.</param>
            <remarks>
            Can be used when all config parameters will be specified through the config object
            and will be instantiated via reflection
            </remarks>
        </member>
        <member name="T:Kafka.Client.Producers.ISyncProducerPool">
            <summary>
            Pool of producers used by producer high-level API
            </summary>
        </member>
        <member name="M:Kafka.Client.Producers.ISyncProducerPool.AddProducer(Kafka.Client.Cluster.Broker)">
            <summary>
            Add a new producer, either synchronous or asynchronous, to the pool
            </summary>
            <param name="broker">The broker informations.</param>
        </member>
        <member name="T:Kafka.Client.Producers.Sync.SyncProducerPool">
            <summary>
            The base for all classes that represents pool of producers used by high-level API
            </summary>
        </member>
        <member name="F:Kafka.Client.Producers.Sync.SyncProducerPool.syncProducers">
            <summary>
            BrokerID  -->  SyncProducer
            </summary>
        </member>
        <member name="M:Kafka.Client.Producers.Sync.SyncProducerPool.Dispose">
            <summary>
            Releases all unmanaged and managed resources
            </summary>
        </member>
        <member name="T:Kafka.Client.Producers.Sync.ISyncProducer">
            <summary>
            Sends messages encapsulated in request to Kafka server synchronously
            </summary>
        </member>
        <member name="M:Kafka.Client.Producers.Sync.ISyncProducer.Send(Kafka.Client.Requests.ProducerRequest)">
            <summary>
            Sends a producer request to Kafka server synchronously
            </summary>
            <param name="request">
            The request.
            </param>
        </member>
        <member name="M:Kafka.Client.Producers.Sync.ISyncProducer.Send(Kafka.Client.Requests.TopicMetadataRequest)">
            <summary>
            Sends a topic metadata request to Kafka server synchronously
            </summary>
            <param name="request">The Request</param>
            <returns>The Response</returns>
        </member>
        <member name="T:Kafka.Client.Producers.Sync.SyncProducer">
            <summary>
            Sends messages encapsulated in request to Kafka server synchronously
            </summary>
        </member>
        <member name="P:Kafka.Client.Producers.Sync.SyncProducer.Config">
            <summary>
            Gets producer config
            </summary>
        </member>
        <member name="M:Kafka.Client.Producers.Sync.SyncProducer.#ctor(Kafka.Client.Cfg.SyncProducerConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Producers.Sync.SyncProducer"/> class.
            </summary>
            <param name="config">
            The producer config.
            </param>
        </member>
        <member name="M:Kafka.Client.Producers.Sync.SyncProducer.Send(Kafka.Client.Requests.ProducerRequest)">
            <summary>
            Sends request to Kafka server synchronously
            </summary>
            <param name="request">
            The request.
            </param>
        </member>
        <member name="M:Kafka.Client.Producers.Sync.SyncProducer.Dispose">
            <summary>
            Releases all unmanaged and managed resources
            </summary>
        </member>
        <member name="M:Kafka.Client.Producers.Sync.SyncProducer.EnsuresNotDisposed">
            <summary>
            Ensures that object was not disposed
            </summary>
        </member>
        <member name="T:Kafka.Client.Producers.TopicData">
            <summary>
            TODO: Update summary.
            </summary>
        </member>
        <member name="T:Kafka.Client.Producers.TopicMetadata">
            <summary>
            TODO: Update summary.
            </summary>
        </member>
        <member name="T:Kafka.Client.Producers.IProducer`2">
            <summary>
            High-level Producer API that exposing all the producer functionality through a single API to the client
            </summary>
            <typeparam name="TKey">The type of the key.</typeparam>
            <typeparam name="TData">The type of the data.</typeparam>
        </member>
        <member name="M:Kafka.Client.Producers.IProducer`2.Send(System.Collections.Generic.IEnumerable{Kafka.Client.Producers.ProducerData{`0,`1}})">
            <summary>
            Sends the data to a multiple topics, partitioned by key, using either the
            synchronous or the asynchronous producer.
            </summary>
            <param name="data">The producer data objects that encapsulate the topic, key and message data.</param>
        </member>
        <member name="M:Kafka.Client.Producers.IProducer`2.Send(Kafka.Client.Producers.ProducerData{`0,`1})">
            <summary>
            Sends the data to a single topic, partitioned by key, using either the
            synchronous or the asynchronous producer.
            </summary>
            <param name="data">The producer data object that encapsulates the topic, key and message data.</param>
        </member>
        <member name="T:Kafka.Client.Producers.ProducerPoolData`1">
            <summary>
            Encapsulates data to be send on chosen partition
            </summary>
            <typeparam name="TData">
            Type of data
            </typeparam>
        </member>
        <member name="M:Kafka.Client.Producers.ProducerPoolData`1.#ctor(System.String,Kafka.Client.Cluster.Partition,System.Collections.Generic.IEnumerable{`0})">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Producers.ProducerPoolData`1"/> class.
            </summary>
            <param name="topic">
            The topic.
            </param>
            <param name="bidPid">
            The chosen partition.
            </param>
            <param name="data">
            The data.
            </param>
        </member>
        <member name="P:Kafka.Client.Producers.ProducerPoolData`1.Topic">
            <summary>
            Gets the topic.
            </summary>
        </member>
        <member name="P:Kafka.Client.Producers.ProducerPoolData`1.BidPid">
            <summary>
            Gets the chosen partition.
            </summary>
        </member>
        <member name="P:Kafka.Client.Producers.ProducerPoolData`1.Data">
            <summary>
            Gets the data.
            </summary>
        </member>
        <member name="T:Kafka.Client.Producers.ProducerData`2">
            <summary>
            Encapsulates data to be send on topic
            </summary>
            <typeparam name="TKey">
            Type of partitioning key
            </typeparam>
            <typeparam name="TData">
            Type of data
            </typeparam>
        </member>
        <member name="M:Kafka.Client.Producers.ProducerData`2.#ctor(System.String,`0,System.Boolean,System.Collections.Generic.IEnumerable{`1})">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Producers.ProducerData`2"/> class.
            </summary>
            <param name="topic">
            The topic.
            </param>
            <param name="key">
            The partitioning key.
            </param>
            <param name="data">
            The list of data to send on the same topic.
            </param>
        </member>
        <member name="M:Kafka.Client.Producers.ProducerData`2.#ctor(System.String,`0,System.Collections.Generic.IEnumerable{`1})">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Producers.ProducerData`2"/> class.
            </summary>
            <param name="topic">
            The topic.
            </param>
            <param name="key">
            The partitioning key.
            </param>
            <param name="data">
            The list of data to send on the same topic.
            </param>
        </member>
        <member name="M:Kafka.Client.Producers.ProducerData`2.#ctor(System.String,`0,`1)">
            <summary>
             Initializes a new instance of the <see cref="T:Kafka.Client.Producers.ProducerData`2"/> class.
            </summary>
            <param name="topic">The topic.</param>
            <param name="key">The partitioning key.</param>
            <param name="data">The data to send on the topic.</param>
        </member>
        <member name="M:Kafka.Client.Producers.ProducerData`2.#ctor(System.String,System.Collections.Generic.IEnumerable{`1})">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Producers.ProducerData`2"/> class.
            </summary>
            <param name="topic">
            The topic.
            </param>
            <param name="data">
            The list of data to send on the same topic.
            </param>
        </member>
        <member name="M:Kafka.Client.Producers.ProducerData`2.#ctor(System.String,`1)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Producers.ProducerData`2"/> class.
            </summary>
            <param name="topic">
            The topic.
            </param>
            <param name="data">
            The data to send on the topic.
            </param>
        </member>
        <member name="P:Kafka.Client.Producers.ProducerData`2.Topic">
            <summary>
            Gets topic.
            </summary>
        </member>
        <member name="P:Kafka.Client.Producers.ProducerData`2.Key">
            <summary>
            Gets the partitioning key.
            </summary>
        </member>
        <member name="P:Kafka.Client.Producers.ProducerData`2.IsKeyNull">
            <summary>
            Whether partition key is Null or not
            </summary>
        </member>
        <member name="P:Kafka.Client.Producers.ProducerData`2.Data">
            <summary>
            Gets the data.
            </summary>
        </member>
        <member name="T:Kafka.Client.Producers.Producer`2">
            <summary>
            High-level Producer API that exposes all the producer functionality to the client
            </summary>
            <typeparam name="TKey">The type of the key.</typeparam>
            <typeparam name="TData">The type of the data.</typeparam>
            <remarks>
            Provides serialization of data through a user-specified encoder, zookeeper based automatic broker discovery
            and software load balancing through an optionally user-specified partitioner
            </remarks>
        </member>
        <member name="M:Kafka.Client.Producers.Producer`2.Send(System.Collections.Generic.IEnumerable{Kafka.Client.Producers.ProducerData{`0,`1}})">
            <summary>
            Sends the data to a multiple topics, partitioned by key
            </summary>
            <param name="data">The producer data objects that encapsulate the topic, key and message data.</param>
        </member>
        <member name="M:Kafka.Client.Producers.Producer`2.Send(Kafka.Client.Producers.ProducerData{`0,`1})">
            <summary>
            Sends the data to a single topic, partitioned by key, using either the
            synchronous or the asynchronous producer.
            </summary>
            <param name="data">The producer data object that encapsulates the topic, key and message data.</param>
        </member>
        <member name="M:Kafka.Client.Producers.Producer`2.EnsuresNotDisposed">
            <summary>
            Ensures that object was not disposed
            </summary>
        </member>
        <member name="T:Kafka.Client.RequestContext`1">
            <summary>
            The context of a request made to Kafka.
            </summary>
            <typeparam name="T">
            Must be of type <see cref="T:Kafka.Client.Requests.AbstractRequest"/> and represents the type of request
            sent to Kafka.
            </typeparam>
        </member>
        <member name="M:Kafka.Client.RequestContext`1.#ctor(System.Net.Sockets.NetworkStream,`0)">
            <summary>
            Initializes a new instance of the RequestContext class.
            </summary>
            <param name="networkStream">The network stream that sent the message.</param>
            <param name="request">The request sent over the stream.</param>
        </member>
        <member name="P:Kafka.Client.RequestContext`1.NetworkStream">
            <summary>
            Gets the <see cref="P:Kafka.Client.RequestContext`1.NetworkStream"/> instance of the request.
            </summary>
        </member>
        <member name="P:Kafka.Client.RequestContext`1.Request">
            <summary>
            Gets the <see cref="T:Kafka.Client.Requests.FetchRequest"/> or <see cref="T:Kafka.Client.Requests.ProducerRequest"/> object
            associated with the <see cref="!:RequestContext"/>.
            </summary>
        </member>
        <member name="T:Kafka.Client.Requests.FetchRequestBuilder">
            <summary>
            TODO: Update summary.
            </summary>
        </member>
        <member name="T:Kafka.Client.Requests.TopicMetadataRequest">
            <summary>
            Kafka request to get topic metadata.
            </summary>
        </member>
        <member name="M:Kafka.Client.Requests.TopicMetadataRequest.Create(System.Collections.Generic.IEnumerable{System.String},System.Int16,System.Int32,System.String)">
            <summary>
            Creates simple request with no segment metadata information
            </summary>
            <param name="topics">list of topics</param>
            <param name="versionId"></param>
            <param name="correlationId"></param>
            <param name="clientId"></param>
            <returns>request</returns>
        </member>
        <member name="T:Kafka.Client.Requests.TopicMetadataRequest.Parser">
            <summary>
            https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol
            MetadataResponse => [Broker][TopicMetadata]
              Broker => NodeId Host Port
                NodeId => int32
                Host => string
                Port => int32
              TopicMetadata => TopicErrorCode TopicName [PartitionMetadata]
                TopicErrorCode => int16
                PartitionMetadata => PartitionErrorCode PartitionId Leader Replicas Isr
                    PartitionErrorCode => int16
                    PartitionId => int32
                    Leader => int32
                    Replicas => [int32]
                    Isr => [int32]
            </summary>
        </member>
        <member name="T:Kafka.Client.Requests.AbstractRequest">
            <summary>
            Base request to make to Kafka.
            </summary>
        </member>
        <member name="T:Kafka.Client.Requests.FetchRequest">
            <summary>
            Constructs a request to send to Kafka.
            FetchRequest => ReplicaId MaxWaitTime MinBytes [TopicName [Partition FetchOffset MaxBytes]]
            ReplicaId => int32
            MaxWaitTime => int32
            MinBytes => int32
            TopicName => string
            Partition => int32
            FetchOffset => int64
            MaxBytes => int32
            set MaxWaitTime  to 0 and MinBytes to 0 can reduce latency.
            </summary>
        </member>
        <member name="M:Kafka.Client.Requests.FetchRequest.WriteTo(System.IO.MemoryStream)">
            <summary>
            Writes content into given stream
            </summary>
            <param name="output">
            The output stream.
            </param>
        </member>
        <member name="M:Kafka.Client.Requests.FetchRequest.WriteTo(Kafka.Client.Serialization.KafkaBinaryWriter)">
            <summary>
            Writes content into given writer
            </summary>
            <param name="writer">
            The writer.
            </param>
        </member>
        <member name="T:Kafka.Client.Requests.OffsetRequest">
            <summary>
            Constructs a request to send to Kafka to get the current offset for a given topic
            </summary>
        </member>
        <member name="F:Kafka.Client.Requests.OffsetRequest.LatestTime">
            <summary>
            The latest time constant.
            </summary>
        </member>
        <member name="F:Kafka.Client.Requests.OffsetRequest.EarliestTime">
            <summary>
            The earliest time constant.
            </summary>
        </member>
        <member name="M:Kafka.Client.Requests.OffsetRequest.#ctor(System.Collections.Generic.Dictionary{System.String,System.Collections.Generic.List{Kafka.Client.Requests.PartitionOffsetRequestInfo}},System.Int16,System.Int32,System.String,System.Int32)">
            <summary>
            Initializes a new instance of the OffsetRequest class.
            </summary>        
        </member>
        <member name="M:Kafka.Client.Requests.OffsetRequest.WriteTo(System.IO.MemoryStream)">
            <summary>
            Writes content into given stream
            </summary>
            <param name="output">
            The output stream.
            </param>
        </member>
        <member name="M:Kafka.Client.Requests.OffsetRequest.WriteTo(Kafka.Client.Serialization.KafkaBinaryWriter)">
            <summary>
            Writes content into given writer
            </summary>
            <param name="writer">
            The writer.
            </param>
        </member>
        <member name="T:Kafka.Client.Requests.ProducerRequest">
            <summary>
            Constructs a request to send to Kafka.
            </summary>
        </member>
        <member name="M:Kafka.Client.Requests.ProducerRequest.#ctor(System.Int32,System.String,System.Int16,System.Int32,System.Collections.Generic.IEnumerable{Kafka.Client.Producers.TopicData})">
            <summary>
            This function should be obsolete since it's not sync with java version.
            </summary>
            <param name="correlationId"></param>
            <param name="clientId"></param>
            <param name="requiredAcks"></param>
            <param name="ackTimeout"></param>
            <param name="data"></param>
        </member>
        <member name="M:Kafka.Client.Requests.ProducerRequest.#ctor(System.Int32,System.String,System.Int16,System.Int32,System.Collections.Generic.IDictionary{Kafka.Client.Responses.TopicAndPartition,Kafka.Client.Messages.BufferedMessageSet})">
            <summary>
            Based on messageset per topic/partition, group it by topic and send out.
            Sync with java/scala version , do group by topic inside this class.
            https://git-wip-us.apache.org/repos/asf?p=kafka.git;a=blob;f=core/src/main/scala/kafka/api/ProducerRequest.scala;h=570b2da1d865086f9830aa919a49063abbbe574d;hb=HEAD
            private lazy val dataGroupedByTopic = data.groupBy(_._1.topic)
            </summary>
            <param name="correlationId"></param>
            <param name="clientId"></param>
            <param name="requiredAcks"></param>
            <param name="ackTimeout"></param>
            <param name="messagesPerTopic"></param>
        </member>
        <member name="M:Kafka.Client.Requests.ProducerRequest.WriteTo(System.IO.MemoryStream)">
            <summary>
            Writes content into given stream
            </summary>
            <param name="output">
            The output stream.
            </param>
        </member>
        <member name="M:Kafka.Client.Requests.ProducerRequest.WriteTo(Kafka.Client.Serialization.KafkaBinaryWriter)">
            <summary>
            Writes content into given writer
            </summary>
            <param name="writer">
            The writer.
            </param>
        </member>
        <member name="T:Kafka.Client.Requests.RequestTypes">
            <summary>
            Requests types for Kafka
            </summary>
            <remarks>
            Many of these are not in play yet.
            See https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol
            </remarks>
        </member>
        <member name="F:Kafka.Client.Requests.RequestTypes.Produce">
            <summary>
            Produce a message.
            </summary>
        </member>
        <member name="F:Kafka.Client.Requests.RequestTypes.Fetch">
            <summary>
            Fetch a message.
            </summary>
        </member>
        <member name="F:Kafka.Client.Requests.RequestTypes.Offsets">
            <summary>
            Gets offsets.
            </summary>
        </member>
        <member name="F:Kafka.Client.Requests.RequestTypes.TopicMetadataRequest">
            <summary>
            Gets topic metadata
            </summary>
        </member>
        <member name="T:Kafka.Client.Responses.FetchResponse">
            <summary>
            TODO: Update summary.
            </summary>
        </member>
        <member name="T:Kafka.Client.Serialization.StringEncoder">
            <summary>
            Serializes data to <see cref="T:Kafka.Client.Messages.Message" /> format using UTF-8 encoding
            </summary>
        </member>
        <member name="M:Kafka.Client.Serialization.StringEncoder.ToMessage(System.String)">
            <summary>
            Serializes given data to <see cref="T:Kafka.Client.Messages.Message" /> format using UTF-8 encoding
            </summary>
            <param name="data">
            The data to serialize.
            </param>
            <returns>
            Serialized data
            </returns>
        </member>
        <member name="T:Kafka.Client.Serialization.IWritable">
            <summary>
            Writes content into given stream
            </summary>
        </member>
        <member name="M:Kafka.Client.Serialization.IWritable.WriteTo(System.IO.MemoryStream)">
            <summary>
            Writes content into given stream
            </summary>
            <param name="output">
            The output stream.
            </param>
        </member>
        <member name="M:Kafka.Client.Serialization.IWritable.WriteTo(Kafka.Client.Serialization.KafkaBinaryWriter)">
            <summary>
            Writes content into given writer
            </summary>
            <param name="writer">
            The writer.
            </param>
        </member>
        <member name="T:Kafka.Client.Serialization.DefaultEncoder">
            <summary>
            Default serializer that expects <see cref="T:Kafka.Client.Messages.Message" /> object
            </summary>
        </member>
        <member name="M:Kafka.Client.Serialization.DefaultEncoder.ToMessage(Kafka.Client.Messages.Message)">
            <summary>
            Do nothing with data
            </summary>
            <param name="data">
            The data, that are already in <see cref="T:Kafka.Client.Messages.Message" /> format.
            </param>
            <returns>
            Serialized data
            </returns>
        </member>
        <member name="T:Kafka.Client.Serialization.KafkaBinaryReader">
            <summary>
            Reads data from underlying stream using big endian bytes order for primitive types
            and UTF-8 encoding for strings.
            </summary>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryReader.#ctor(System.IO.Stream)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Serialization.KafkaBinaryReader"/> class
            using big endian bytes order for primive types and UTF-8 encoding for strings.
            </summary>
            <param name="input">
            The input stream.
            </param>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryReader.Dispose(System.Boolean)">
            <summary>
            Resets position pointer.
            </summary>
            <param name="disposing">
            Not used
            </param>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryReader.ReadInt16">
            <summary>
            Reads two-bytes signed integer from the current stream using big endian bytes order 
            and advances the stream position by two bytes
            </summary>
            <returns>
            The two-byte signed integer read from the current stream.
            </returns>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryReader.ReadInt32">
            <summary>
            Reads four-bytes signed integer from the current stream using big endian bytes order 
            and advances the stream position by four bytes
            </summary>
            <returns>
            The four-byte signed integer read from the current stream.
            </returns>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryReader.ReadInt64">
            <summary>
            Reads eight-bytes signed integer from the current stream using big endian bytes order 
            and advances the stream position by eight bytes
            </summary>
            <returns>
            The eight-byte signed integer read from the current stream.
            </returns>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryReader.Read">
            <summary>
            Reads four-bytes signed integer from the current stream using big endian bytes order 
            and advances the stream position by four bytes
            </summary>
            <returns>
            The four-byte signed integer read from the current stream.
            </returns>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryReader.ReadShortString(System.String)">
            <summary>
            Reads fixed-length short string from underlying stream using given encoding.
            </summary>
            <param name="encoding">
            The encoding to use.
            </param>
            <returns>
            The read string.
            </returns>
        </member>
        <member name="T:Kafka.Client.Serialization.KafkaBinaryWriter">
            <summary>
            Writes data into underlying stream using big endian bytes order for primitive types     
            and UTF-8 encoding for strings.
            </summary>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryWriter.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Serialization.KafkaBinaryWriter"/> class 
            using big endian bytes order for primive types and UTF-8 encoding for strings.
            </summary>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryWriter.#ctor(System.IO.MemoryStream)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.Serialization.KafkaBinaryWriter"/> class 
            using big endian bytes order for primive types and UTF-8 encoding for strings.
            </summary>
            <param name="output">
            The output stream.
            </param>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryWriter.Dispose(System.Boolean)">
            <summary>
            Flushes data into stream and resets position pointer.
            </summary>
            <param name="disposing">
            Not used
            </param>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryWriter.Write(System.Int32)">
            <summary>
            Writes four-bytes signed integer to the current stream using big endian bytes order 
            and advances the stream position by four bytes
            </summary>
            <param name="value">
            The value to write.
            </param>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryWriter.Write(System.Int64)">
            <summary>
            Writes eight-bytes signed integer to the current stream using big endian bytes order 
            and advances the stream position by eight bytes
            </summary>
            <param name="value">
            The value to write.
            </param>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryWriter.Write(System.Int16)">
            <summary>
            Writes two-bytes signed integer to the current stream using big endian bytes order 
            and advances the stream position by two bytes
            </summary>
            <param name="value">
            The value to write.
            </param>
        </member>
        <member name="M:Kafka.Client.Serialization.KafkaBinaryWriter.WriteShortString(System.String,System.String)">
            <summary>
            Writes topic and his size into underlying stream using given encoding.
            </summary>
            <param name="topic">
            The topic to write.
            </param>
            <param name="encoding">
            The encoding to use.
            </param>
        </member>
        <member name="T:Kafka.Client.Serialization.IEncoder`1">
            <summary>
            User-defined serializer to <see cref="T:Kafka.Client.Messages.Message" /> format
            </summary>
            <typeparam name="TData">
            Type od data
            </typeparam>
        </member>
        <member name="M:Kafka.Client.Serialization.IEncoder`1.ToMessage(`0)">
            <summary>
            Serializes given data to <see cref="T:Kafka.Client.Messages.Message" /> format
            </summary>
            <param name="data">
            The data to serialize.
            </param>
            <returns>
            Serialized data
            </returns>
        </member>
        <member name="T:Kafka.Client.KafkaClientBase">
            <summary>
            Base class for all Kafka clients
            </summary>
        </member>
        <member name="M:Kafka.Client.KafkaClientBase.Dispose">
            <summary>
            Releases all unmanaged and managed resources
            </summary>
        </member>
        <member name="M:Kafka.Client.KafkaClientBase.Dispose(System.Boolean)">
            <summary>
            Releases all unmanaged and managed resources
            </summary>
            <param name="disposing">
            Indicates whether release managed resources.
            </param>
        </member>
        <member name="T:Kafka.Client.Utils.ClusterHealthChecker">
            <summary>
            Helper class to inspect Kafka and Zookeper cluster health (eg. Topics partitions, brokers availability).
            </summary>
        </member>
        <member name="M:Kafka.Client.Utils.ClusterHealthChecker.GetZooKeeperTopicsPartitionsState(System.Collections.Generic.ICollection{System.String})">
            <summary>
            Get state of all partitions for specified topics. If topics not specified will automatically retrieve all topics within a cluster
            </summary>
            <param name="topics">Topics name to inspect. If topics are null <see cref="T:Kafka.Client.Utils.ClusterHealthChecker"/> will automatically retrieve all topics from ZooKeeper servers</param>
            <returns>Dictionary where Key is topic name and Value is another Dictionary of partitions states for that topic.</returns>
            <remarks>If topics are null <see cref="T:Kafka.Client.Utils.ClusterHealthChecker"/> will automatically retrieve all topics within a cluster</remarks>
        </member>
        <member name="M:Kafka.Client.Utils.ClusterHealthChecker.GetKafkaBrokersAliveState(System.Collections.Generic.ICollection{Kafka.Client.Cluster.Broker})">
            <summary>
            Check that brokers alive by sending topic metadata request to them
            </summary>
            <param name="brokers">Collection of brokers to check. If null - brokers list will be retrieved from ZooKeeper state</param>
            <returns>
                Dictionary where Key is Broker Id and Value indicates whether Broker responds to requests. 
                Value is true when Broker TopicMetadataRequest was successfully sent to broker and any response was recieved back.
                Value is false when connection to Broker failed or 
             </returns>
            <remarks>
            If brokers not specified this method will only ping brokers that exist in ZooKeeper state
            </remarks>
        </member>
        <member name="M:Kafka.Client.Utils.ClusterHealthChecker.GetZooKeeperHostsAliveState">
            <summary>
            Check that ZooKeeper VMs alive by sending telnet command to each server
            </summary>
            <returns>
                Dictionary where Key is ZooKeeper host name and Value dictionary of IPAddress and ping result. 
                Ping result value is true when successfully connected to ZooKeeper VM and it successfully responded to TELNET command "ruok".
                Otherwise Value is false.
             </returns>
        </member>
        <member name="M:Kafka.Client.Utils.ClusterHealthChecker.GetZooKeeperHostsAliveState(System.Collections.Generic.List{System.Exception}@)">
            <summary>
            Check that ZooKeeper VMs alive by sending telnet command to each server
            </summary>
            <param name="errorList">The list of errors occured while check was performed</param>
            <returns>
                Dictionary where Key is ZooKeeper host name and Value dictionary of IPAddress and ping result. 
                Ping result value is true when successfully connected to ZooKeeper VM and it successfully responded to TELNET command "ruok".
                Otherwise Value is false.
             </returns>
        </member>
        <member name="M:Kafka.Client.Utils.ClusterHealthChecker.PingZooKeeperHost(System.Net.IPEndPoint)">
            <summary>
            Send "ruok" command (ping command analog) to ZooKeeper server with specified Ip Address and port
            </summary>
            <param name="addr">The IP Address and port</param>
            <returns>True if was able to connect to server, send "ruok" command and recieve "imok" back. Otherwise throws exception with error description</returns>
        </member>
        <member name="T:Kafka.Client.Utils.ConsumerOffsetChecker">
            <summary>
            Helper class to collect statistics about Consumer's offsets, lags, etc.
            </summary>
        </member>
        <member name="M:Kafka.Client.Utils.ConsumerOffsetChecker.GetConsumerStatistics(System.Collections.Generic.ICollection{System.String},System.String)">
            <summary>
            Get the statistics about how many messages left in queue unconsumed by specified consumer group
            </summary>
            <param name="topics">Topics name that Consumer Group started consuming. If topics are null <see cref="T:Kafka.Client.Utils.ConsumerOffsetChecker"/> will automatically retrieve all topics for specified Consumer Group</param>
            <param name="consumerGroup">Consumer group name</param>
            <returns><see cref="T:Kafka.Client.Consumers.ConsumerGroupStatisticsRecord"/> that contains statistics of consuming specified topics by specified consumer group. If topics are null <see cref="T:Kafka.Client.Utils.ConsumerOffsetChecker"/> will automatically retrieve all topics for specified Consumer Group</returns>
            <remarks>If topics are null <see cref="T:Kafka.Client.Utils.ConsumerOffsetChecker"/> will automatically retrieve all topics for specified Consumer Group</remarks>
        </member>
        <member name="M:Kafka.Client.Utils.ConsumerOffsetChecker.GetConsumer(System.Int32)">
            <summary>
            Get consumer instance for specified broker from cache. Or create a consumer if it does not already exist.
            </summary>
            <param name="brokerId">Broker id</param>
            <returns>Consumer instance for specified broker.</returns>
        </member>
        <member name="T:Kafka.Client.Utils.ConsumerUtils">
            <summary>
            helper methods to use with Kafka <see cref="T:Kafka.Client.Consumers.Consumer"/> instances
            </summary>
        </member>
        <member name="M:Kafka.Client.Utils.ConsumerUtils.EarliestOrLatestOffset(Kafka.Client.Consumers.Consumer,System.String,System.Int32,System.Int64)">
            <summary>
            Retrive first or last offset for a given partition.
            </summary>
            <remarks>
            If <see cref="!:offsetRequestConstant"/> not equal to <see cref="F:Kafka.Client.Requests.OffsetRequest.LatestTime"/> or <see cref="F:Kafka.Client.Requests.OffsetRequest.EarliestTime"/> method returns offset before specified number.
            </remarks>
            <param name="consumer">Consumer instance</param>
            <param name="topic">The topic</param>
            <param name="partitionId">Partition Id</param>
            <param name="offsetRequestConstant">Offset that indicates what offset need to return.</param>
            <returns>
            Retrive first or last offset for a given partition based on <see cref="!:offsetRequestConstant"/> parameter.
            If offset couldn't be retrieved returns null.
            </returns>
        </member>
        <member name="T:Kafka.Client.Utils.ErrorMapping">
            <summary>
            https://cwiki.apache.org/confluence/display/KAFKA/A+Guide+To+The+Kafka+Protocol
            </summary>
        </member>
        <member name="M:Kafka.Client.Utils.Guard.Assert``1(System.Linq.Expressions.Expression{System.Func{System.Boolean}})">
            <summary>
            Checks whether given expression is true. Throws given exception type if not.
            </summary>
            <typeparam name="TException">
            Type of exception that i thrown when condition is not met.
            </typeparam>
            <param name="assertion">
            The assertion.
            </param>
        </member>
        <member name="M:Kafka.Client.Utils.Guard.Normalize(System.String)">
            <summary>
            Creates string representation of lambda expression with unnecessary information 
            stripped out. 
            </summary>
            <param name="expression">Lambda expression to process. </param>
            <returns>Normalized string representation. </returns>
        </member>
        <member name="T:Kafka.Client.Utils.KafkaConsoleUtil">
            <summary>
            This class mainly for KafkaNETLibraryConsole, maybe will change even break without any notification.
            </summary>
        </member>
        <member name="T:Kafka.Client.Utils.KafkaScheduler">
            <summary>
            A scheduler for running jobs in the background
            </summary>
        </member>
        <member name="T:Kafka.Client.Utils.Crc32Hasher">
            <summary>
            From http://damieng.com/blog/2006/08/08/calculating_crc32_in_c_and_net
            </summary>
        </member>
        <member name="T:Kafka.Client.Utils.BitWorks">
            <summary>
            Utilty class for managing bits and bytes.
            </summary>
        </member>
        <member name="M:Kafka.Client.Utils.BitWorks.GetBytesReversed(System.Int16)">
            <summary>
            Converts the value to bytes and reverses them.
            </summary>
            <param name="value">The value to convert to bytes.</param>
            <returns>Bytes representing the value.</returns>
        </member>
        <member name="M:Kafka.Client.Utils.BitWorks.GetBytesReversed(System.Int32)">
            <summary>
            Converts the value to bytes and reverses them.
            </summary>
            <param name="value">The value to convert to bytes.</param>
            <returns>Bytes representing the value.</returns>
        </member>
        <member name="M:Kafka.Client.Utils.BitWorks.GetBytesReversed(System.Int64)">
            <summary>
            Converts the value to bytes and reverses them.
            </summary>
            <param name="value">The value to convert to bytes.</param>
            <returns>Bytes representing the value.</returns>
        </member>
        <member name="M:Kafka.Client.Utils.BitWorks.ReverseBytes(System.Byte[])">
            <summary>
            Reverse the position of an array of bytes.
            </summary>
            <param name="inArray">
            The array to reverse.  If null or zero-length then the returned array will be null.
            </param>
            <returns>The reversed array.</returns>
        </member>
        <member name="M:Kafka.Client.Utils.BitWorks.GetShortStringLength(System.String,System.String)">
            <summary>
            Return size of a size prefixed string where the size is stored as a 2 byte short
            </summary>
            <param name="text">The string to write</param>
            <param name="encoding">The encoding in which to write the string</param>
            <returns></returns>
        </member>
        <member name="T:Kafka.Client.ZooKeeperAwareKafkaClientBase">
            <summary>
            A base class for all Kafka clients that support ZooKeeper based automatic broker discovery
            </summary>
        </member>
        <member name="M:Kafka.Client.ZooKeeperAwareKafkaClientBase.#ctor(Kafka.Client.Cfg.ZooKeeperConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Kafka.Client.ZooKeeperAwareKafkaClientBase"/> class.
            </summary>
            <param name="config">The config.</param>
        </member>
        <member name="P:Kafka.Client.ZooKeeperAwareKafkaClientBase.IsZooKeeperEnabled">
            <summary>
            Gets a value indicating whether ZooKeeper based automatic broker discovery is enabled.
            </summary>
            <value>
            <c>true</c> if this instance is zoo keeper enabled; otherwise, <c>false</c>.
            </value>
        </member>
        <member name="M:KafkaNET.Library.Examples.TestHelper.Run(KafkaNET.Library.Examples.TestHelperOptions)">
            <summary>
            Run one test case
            </summary>
            <param name="testOptions"></param>
        </member>
        <member name="M:KafkaNET.Library.Examples.TestHelper.TestBug1490652(KafkaNET.Library.Examples.TestHelperOptions)">
            <summary>
            Previously , the wrong exception hit when:
                One broker is leader of multiple partition(>=2).
                Send a group of message, and they need go to different partitions of the same broker.
            Preparation before run the case:
                Assume we have 3 broker, then create topic as
                    .\bin\kafka.cmd topiccmd --create --topic mvlogsA --partition 4 --replication-factor 1 --zookeeper localhost
                Then run this case by send more than 5 messages.
            </summary>
            <param name="testOptions"></param>
            <returns></returns>
        </member>
        <member name="T:KafkaNET.Library.Examples.ConsumeGroupHelperOptions">
            <summary>
            ConsumeGroup
            TODO: Currently this example only support consume from beginning of partitions. Can be extend.
            </summary>
        </member>
        <member name="T:KafkaNET.Library.Examples.ConsumerGroupHelper">
            <summary>
            Examples of using ConsumerGroup.
            Single thread or multiple threads.
            </summary>
        </member>
        <member name="T:KafkaNET.Library.Examples.KafkaNetLibraryExample">
            <summary>
            You can copy out code of this class, the code under namespace KafkaNET.Library.Examples maybe change without notification.
            </summary>
        </member>
        <member name="T:KafkaNET.Library.Examples.ProducePerfTestKafkaSimpleManagerWrapper">
            <summary>
            Probably you need copy out this class to manger the KafkaSimpleManager.
            </summary>
        </member>
        <member name="T:KafkaNET.Library.Examples.ProduceSimpleHelper">
            <summary>
            Single thread to produce to demo the basic process of produce data.
            When leader of some partition changed, will catch exception and recreate producer for all partitions.
            For better efficient example, check ProducePerfTestHelper.cs.
            </summary>
        </member>
        <member name="T:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter">
            <summary>
            Represents an exception formatter that formats exception objects as XML.
            </summary>	
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.#ctor(System.Xml.XmlWriter,System.Exception,System.Guid)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter"/> class using the specified <see cref="T:System.Xml.XmlWriter"/> and <see cref="T:System.Exception"/> objects.
            </summary>
            <param name="xmlWriter">The <see cref="T:System.Xml.XmlWriter"/> in which to write the XML.</param>
            <param name="exception">The <see cref="T:System.Exception"/> to format.</param>
            <param name="handlingInstanceId">The id of the handling chain.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.#ctor(System.IO.TextWriter,System.Exception,System.Guid)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter"/> class using the specified <see cref="T:System.IO.TextWriter"/> and <see cref="T:System.Exception"/> objects.
            </summary>
            <param name="writer">The <see cref="T:System.IO.TextWriter"/> in which to write the XML.</param>
            <param name="exception">The <see cref="T:System.Exception"/> to format.</param>
            <remarks>
            An <see cref="T:System.Xml.XmlTextWriter"/> with indented formatting is created from the  specified <see cref="T:System.IO.TextWriter"/>.
            </remarks>
            <param name="handlingInstanceId">The id of the handling chain.</param>
        </member>
        <member name="P:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.Writer">
            <summary>
            Gets the underlying <see cref="T:System.Xml.XmlWriter"/> that the formatted exception is written to.
            </summary>
            <value>
            The underlying <see cref="T:System.Xml.XmlWriter"/> that the formatted exception is written to.
            </value>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.Format">
            <summary>
            Formats the <see cref="T:System.Exception"/> into the underlying stream.
            </summary>       
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteDateTime(System.DateTime)">
            <summary>
            Writes the current date and time to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="datetime">The current time.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteMessage(System.String)">
            <summary>
            Writes the value of the <see cref="P:System.Exception.Message"/> property to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="message">The message to write.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteDescription">
            <summary>
            Writes a generic description to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteHelpLink(System.String)">
            <summary>
            Writes the value of the specified help link taken
            from the value of the <see cref="P:System.Exception.HelpLink"/>
            property to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="helpLink">The exception's help link.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteStackTrace(System.String)">
            <summary>
            Writes the value of the specified stack trace taken from the value of the <see cref="P:System.Exception.StackTrace"/> property to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="stackTrace">The stack trace of the exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteSource(System.String)">
            <summary>
            Writes the value of the specified source taken from the value of the <see cref="P:System.Exception.Source"/> property to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="source">The source of the exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteExceptionType(System.Type)">
            <summary>
            Writes the value of the <see cref="P:System.Type.AssemblyQualifiedName"/>
            property for the specified exception type to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="exceptionType">The <see cref="T:System.Type"/> of the exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteException(System.Exception,System.Exception)">
            <summary>
            Writes and formats the exception and all nested inner exceptions to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="exceptionToFormat">The exception to format.</param>
            <param name="outerException">The outer exception. This value will be null when writing the outer-most exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WritePropertyInfo(System.Reflection.PropertyInfo,System.Object)">
            <summary>
            Writes the name and value of the specified property to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="propertyInfo">The reflected <see cref="T:System.Reflection.PropertyInfo"/> object.</param>
            <param name="value">The value of the <see cref="T:System.Reflection.PropertyInfo"/> object.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteFieldInfo(System.Reflection.FieldInfo,System.Object)">
            <summary>
            Writes the name and value of the <see cref="T:System.Reflection.FieldInfo"/> object to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="fieldInfo">The reflected <see cref="T:System.Reflection.FieldInfo"/> object.</param>
            <param name="value">The value of the <see cref="T:System.Reflection.FieldInfo"/> object.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.XmlExceptionFormatter.WriteAdditionalInfo(System.Collections.Specialized.NameValueCollection)">
            <summary>
            Writes additional information to the <see cref="T:System.Xml.XmlWriter"/>.
            </summary>
            <param name="additionalInformation">Additional information to be included with the exception report</param>
        </member>
        <member name="T:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter">
            <summary>
            Represents an exception formatter that formats exception objects as text.
            </summary>	
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.#ctor(System.IO.TextWriter,System.Exception)">
            <summary>
            Initializes a new instance of the 
            <see cref="T:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter"/> using the specified
            <see cref="T:System.IO.TextWriter"/> and <see cref="T:System.Exception"/>
            objects.
            </summary>
            <param name="writer">The stream to write formatting information to.</param>
            <param name="exception">The exception to format.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.#ctor(System.IO.TextWriter,System.Exception,System.Guid)">
            <summary>
            Initializes a new instance of the 
            <see cref="T:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter"/> using the specified
            <see cref="T:System.IO.TextWriter"/> and <see cref="T:System.Exception"/>
            objects.
            </summary>
            <param name="writer">The stream to write formatting information to.</param>
            <param name="exception">The exception to format.</param>
            <param name="handlingInstanceId">The id of the handling chain.</param>
        </member>
        <member name="P:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.Writer">
            <summary>
            Gets the underlying <see cref="T:System.IO.TextWriter"/>
            that the current formatter is writing to.
            </summary>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.Format">
            <summary>
            Formats the <see cref="T:System.Exception"/> into the underlying stream.
            </summary>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteDescription">
            <summary>
            Writes a generic description to the underlying text stream.
            </summary>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteException(System.Exception,System.Exception)">
            <summary>
            Writes and formats the exception and all nested inner exceptions to the <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="exceptionToFormat">The exception to format.</param>
            <param name="outerException">The outer exception. This 
            value will be null when writing the outer-most exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteDateTime(System.DateTime)">
            <summary>
            Writes the current date and time to the <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="datetime">The current time.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteExceptionType(System.Type)">
            <summary>
            Writes the value of the <see cref="P:System.Type.AssemblyQualifiedName"/>
            property for the specified exception type to the <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="exceptionType">The <see cref="T:System.Type"/> of the exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteMessage(System.String)">
            <summary>
            Writes the value of the <see cref="P:System.Exception.Message"/>
            property to the underyling <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="message">The message to write.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteSource(System.String)">
            <summary>
            Writes the value of the specified source taken
            from the value of the <see cref="P:System.Exception.Source"/>
            property to the <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="source">The source of the exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteHelpLink(System.String)">
            <summary>
            Writes the value of the specified help link taken
            from the value of the <see cref="P:System.Exception.HelpLink"/>
            property to the <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="helpLink">The exception's help link.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WritePropertyInfo(System.Reflection.PropertyInfo,System.Object)">
            <summary>
            Writes the name and value of the specified property to the <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="propertyInfo">The reflected <see cref="T:System.Reflection.PropertyInfo"/> object.</param>
            <param name="value">The value of the <see cref="T:System.Reflection.PropertyInfo"/> object.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteFieldInfo(System.Reflection.FieldInfo,System.Object)">
            <summary>
            Writes the name and value of the specified field to the <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="fieldInfo">The reflected <see cref="T:System.Reflection.FieldInfo"/> object.</param>
            <param name="value">The value of the <see cref="T:System.Reflection.FieldInfo"/> object.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteStackTrace(System.String)">
            <summary>
            Writes the value of the <see cref="P:System.Exception.StackTrace"/> property to the <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="stackTrace">The stack trace of the exception.</param>
            <remarks>
            If there is no stack trace available, an appropriate message will be displayed.
            </remarks>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.WriteAdditionalInfo(System.Collections.Specialized.NameValueCollection)">
            <summary>
            Writes the additional properties to the <see cref="T:System.IO.TextWriter"/>.
            </summary>
            <param name="additionalInformation">Additional information to be included with the exception report</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.TextExceptionFormatter.Indent">
            <summary>
            Indents the <see cref="T:System.IO.TextWriter"/>.
            </summary>
        </member>
        <member name="T:Microsoft.KafkaNET.Library.Util.ExceptionFormatter">
            <summary>
            Represents the base class from which all implementations of exception formatters must derive. The formatter provides functionality for formatting <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> objects.
            </summary>	
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.#ctor(System.Exception,System.Guid)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.KafkaNET.Library.Util.ExceptionFormatter"/> class with an <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> to format.
            </summary>
            <param name="exception">The <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> object to format.</param>
            <param name="handlingInstanceId">The id of the handling chain.</param>
        </member>
        <member name="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception">
            <summary>
            Gets the <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> to format.
            </summary>
            <value>
            The <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> to format.
            </value>
        </member>
        <member name="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.HandlingInstanceId">
            <summary>
            Gets the id of the handling chain requesting a formatting.
            </summary>
            <value>
            The id of the handling chain requesting a formatting, or <see cref="F:System.Guid.Empty"/> if no such id is available.
            </value>
        </member>
        <member name="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.AdditionalInfo">
            <summary>
            Gets additional information related to the <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> but not
            stored in the exception (eg: the time in which the <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> was 
            thrown).
            </summary>
            <value>
            Additional information related to the <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> but not
            stored in the exception (for example, the time when the <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> was 
            thrown).
            </value>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Format">
            <summary>
            Formats the <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> into the underlying stream.
            </summary>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteException(System.Exception,System.Exception)">
            <summary>
            Formats the exception and all nested inner exceptions.
            </summary>
            <param name="exceptionToFormat">The exception to format.</param>
            <param name="outerException">The outer exception. This 
            value will be null when writing the outer-most exception.</param>
            <remarks>
            <para>This method calls itself recursively until it reaches
            an exception that does not have an inner exception.</para>
            <para>
            This is a template method which calls the following
            methods in order
            <list type="number">
            <item>
            <description><see cref="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteExceptionType(System.Type)"/></description>
            </item>
            <item>
            <description><see cref="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteMessage(System.String)"/></description>
            </item>
            <item>
            <description><see cref="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteSource(System.String)"/></description>
            </item>
            <item>
            <description><see cref="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteHelpLink(System.String)"/></description>
            </item>
            <item>
            <description><see cref="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteReflectionInfo(System.Exception)"/></description>
            </item>
            <item>
            <description><see cref="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteStackTrace(System.String)"/></description>
            </item>
            <item>
            <description>If the specified exception has an inner exception
            then it makes a recursive call. <see cref="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteException(System.Exception,System.Exception)"/></description>
            </item>
            </list>
            </para>
            </remarks>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteReflectionInfo(System.Exception)">
            <summary>
            Formats an <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> using reflection to get the information.
            </summary>
            <param name="exceptionToFormat">
            The <see cref="P:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.Exception"/> to be formatted.
            </param>
            <remarks>
            <para>This method reflects over the public, instance properties 
            and public, instance fields
            of the specified exception and prints them to the formatter.  
            Certain property names are ignored
            because they are handled explicitly in other places.</para>
            </remarks>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteDescription">
            <summary>
            When overridden by a class, writes a description of the caught exception.
            </summary>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteDateTime(System.DateTime)">
            <summary>
            When overridden by a class, writes the current time.
            </summary>
            <param name="dateTime">The current time.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteExceptionType(System.Type)">
            <summary>
            When overridden by a class, writes the <see cref="T:System.Type"/> of the current exception.
            </summary>
            <param name="exceptionType">The <see cref="T:System.Type"/> of the exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteMessage(System.String)">
            <summary>
            When overridden by a class, writes the <see cref="P:System.Exception.Message"/>.
            </summary>
            <param name="message">The message to write.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteSource(System.String)">
            <summary>
            When overridden by a class, writes the value of the <see cref="P:System.Exception.Source"/> property.
            </summary>
            <param name="source">The source of the exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteHelpLink(System.String)">
            <summary>
            When overridden by a class, writes the value of the <see cref="P:System.Exception.HelpLink"/> property.
            </summary>
            <param name="helpLink">The help link for the exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteStackTrace(System.String)">
            <summary>
            When overridden by a class, writes the value of the <see cref="P:System.Exception.StackTrace"/> property.
            </summary>
            <param name="stackTrace">The stack trace of the exception.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WritePropertyInfo(System.Reflection.PropertyInfo,System.Object)">
            <summary>
            When overridden by a class, writes the value of a <see cref="T:System.Reflection.PropertyInfo"/> object.
            </summary>
            <param name="propertyInfo">The reflected <see cref="T:System.Reflection.PropertyInfo"/> object.</param>
            <param name="value">The value of the <see cref="T:System.Reflection.PropertyInfo"/> object.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteFieldInfo(System.Reflection.FieldInfo,System.Object)">
            <summary>
            When overridden by a class, writes the value of a <see cref="T:System.Reflection.FieldInfo"/> object.
            </summary>
            <param name="fieldInfo">The reflected <see cref="T:System.Reflection.FieldInfo"/> object.</param>
            <param name="value">The value of the <see cref="T:System.Reflection.FieldInfo"/> object.</param>
        </member>
        <member name="M:Microsoft.KafkaNET.Library.Util.ExceptionFormatter.WriteAdditionalInfo(System.Collections.Specialized.NameValueCollection)">
            <summary>
            When overridden by a class, writes additional properties if available.
            </summary>
            <param name="additionalInformation">Additional information to be included with the exception report</param>
        </member>
    </members>
</doc>
